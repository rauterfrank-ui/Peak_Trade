# Strategy Layer vNext - Implementation Report

**Datum**: 2025-12-23  
**Status**: âœ… Abgeschlossen (Phase 1: Foundation)  
**Ziel**: Tooling Hooks fÃ¼r Optuna/MLflow/Polars/DuckDB vorbereiten, ohne bestehende API zu brechen

---

## Executive Summary

Die Phase 1 "Foundation" fÃ¼r Strategy Layer vNext ist abgeschlossen. Wir haben erfolgreich:

1. âœ… **Tracking Interface** implementiert (Protocol + NoopTracker + MLflowTracker-Stub)
2. âœ… **Config Hooks** hinzugefÃ¼gt (`tracking.*` in default.toml)
3. âœ… **BacktestEngine Integration** mit optionalem Tracker-Parameter
4. âœ… **Parameter Schema** fÃ¼r Strategy-Tuning definiert
5. âœ… **Placeholder Scripts** fÃ¼r zukÃ¼nftige Optuna-Integration
6. âœ… **Unit-Tests** geschrieben (11/11 Tests bestanden)
7. âœ… **Dokumentation** erstellt (`docs/STRATEGY_LAYER_VNEXT.md`)

**Keine Breaking Changes**: Alle bestehenden Tests bleiben grÃ¼n, alte API funktioniert unverÃ¤ndert.

---

## Implementierte Files

### Neue Dateien

| Datei | Zeilen | Beschreibung |
|-------|--------|--------------|
| `src/core/tracking.py` | 400+ | Tracking Interface (Protocol, NoopTracker, MLflowTracker) |
| `src/strategies/parameters.py` | 350+ | Parameter Schema fÃ¼r Strategy-Tuning |
| `scripts/run_study_optuna_placeholder.py` | 200+ | Placeholder fÃ¼r Optuna Study Runner |
| `tests/test_tracking_noop.py` | 200+ | Unit-Tests fÃ¼r Tracking + BacktestEngine Integration |
| `docs/STRATEGY_LAYER_VNEXT.md` | 600+ | VollstÃ¤ndige Dokumentation + Roadmap |

### GeÃ¤nderte Dateien

| Datei | Ã„nderung | Beschreibung |
|-------|----------|--------------|
| `src/core/__init__.py` | +10 Zeilen | Tracking-Exports hinzugefÃ¼gt |
| `src/backtest/engine.py` | +80 Zeilen | Tracker-Parameter + Logging-Hooks |
| `config/default.toml` | +20 Zeilen | `[tracking]` Sektion hinzugefÃ¼gt |

**Total**: ~1900 neue Zeilen Code + Dokumentation

---

## Features im Detail

### 1. Tracking Interface (`src/core/tracking.py`)

**Protocol-basiert**: Flexibel fÃ¼r verschiedene Backends (MLflow, W&B, Comet)

```python
from src.core.tracking import Tracker, NoopTracker, build_tracker_from_config

# Tracker aus Config erstellen
tracker = build_tracker_from_config(config)

# Usage
tracker.start_run("ma_crossover_backtest")
tracker.log_params({"fast_window": 20, "slow_window": 50})
tracker.log_metrics({"sharpe": 1.8, "win_rate": 0.55})
tracker.end_run()
```

**Implementierungen**:
- `NoopTracker`: Default, kein Overhead
- `MLflowTracker`: Optional, nur wenn mlflow installiert
- `build_tracker_from_config()`: Factory mit Fallback-Logik

**Key Features**:
- âœ… Kein Overhead wenn disabled (NoopTracker)
- âœ… Graceful Degradation (MLflow nicht installiert â†’ NoopTracker)
- âœ… Type-Safe (Protocol)
- âœ… Helper: `log_backtest_metadata()` fÃ¼r Standard-Logging

### 2. BacktestEngine Integration

**Optionaler Tracker-Parameter** (Backward-Compatible):

```python
from src.backtest import BacktestEngine
from src.core.tracking import build_tracker_from_config

# Ohne Tracker (wie bisher)
engine = BacktestEngine()

# Mit Tracker (neu, opt-in)
tracker = build_tracker_from_config(config)
engine = BacktestEngine(tracker=tracker)
```

**Auto-Logging**:
- Config Snapshot (Parameter, Initial Capital, Mode)
- Git Commit SHA (wenn verfÃ¼gbar)
- Metriken (Sharpe, Total Return, Win Rate, etc.)

**Beide Backtest-Modi unterstÃ¼tzt**:
- âœ… Legacy-Modus (ohne ExecutionPipeline)
- âœ… ExecutionPipeline-Modus (mit Order-Layer)

### 3. Parameter Schema (`src/strategies/parameters.py`)

**Leichtgewichtig**: Nur Dataclasses, keine schweren Dependencies

```python
from src.strategies.parameters import Param

# Numerischer Parameter
Param(name="fast_window", type="int", default=20, low=5, high=50)

# Float mit Log-Scale (fÃ¼r Learning-Rates)
Param(name="lr", type="float", default=0.01, low=0.001, high=0.1, log_scale=True)

# Kategorisch
Param(name="mode", type="categorical", default="fast", choices=["fast", "slow"])

# Boolean
Param(name="use_filter", type="bool", default=True)
```

**Optional fÃ¼r Strategien**:
```python
class MyStrategy(BaseStrategy):
    @property
    def parameter_schema(self) -> list[Param]:
        return [
            Param(name="window", type="int", default=20, low=5, high=50),
        ]
```

**Keine Pflicht**: Bestehende Strategien funktionieren ohne Schema.

**Utility-Funktionen**:
- `extract_param_dict()`: Default-Werte extrahieren
- `validate_param_dict()`: Werte validieren
- `Param.to_optuna_suggest()`: Optuna Trial-Integration (spÃ¤ter)

### 4. Config Integration

**Neue Sektion in `config/default.toml`**:

```toml
[tracking]
enabled = false
backend = "noop"  # oder "mlflow"

[tracking.mlflow]
tracking_uri = "./mlruns"
experiment_name = "strategy_optimization"
```

**Fallback-Logik**:
1. `enabled=false` â†’ NoopTracker
2. `backend="noop"` â†’ NoopTracker
3. `backend="mlflow"` + installiert â†’ MLflowTracker
4. `backend="mlflow"` + nicht installiert â†’ NoopTracker + Warning

### 5. Placeholder Scripts

**`scripts/run_study_optuna_placeholder.py`**:

```bash
python3 scripts/run_study_optuna_placeholder.py \
    --strategy ma_crossover \
    --config config/config.toml \
    --n-trials 100
```

**Output**:
- Hilfreiche Meldung + Verweis auf Doku
- CLI-Args bereits definiert (fÃ¼r zukÃ¼nftige Implementation)
- Exit-Code 0 (kein Error)

**Status**: Placeholder, noch nicht funktional

---

## Tests

### Test-Suite: `tests/test_tracking_noop.py`

**11 Tests, alle bestanden** âœ…

```bash
python3 -m pytest tests/test_tracking_noop.py -v
# ============================== 11 passed in 0.22s ==============================
```

#### Test-Coverage:

**NoopTracker**:
- âœ… `test_noop_tracker_does_nothing`: Keine Exceptions
- âœ… `test_noop_tracker_with_large_data`: Performance (1000+ Params/Metrics)

**Config Builder**:
- âœ… `test_build_tracker_disabled`: tracking.enabled=false
- âœ… `test_build_tracker_noop_backend`: backend="noop"
- âœ… `test_build_tracker_missing_config`: Fehlende Config
- âœ… `test_build_tracker_unknown_backend`: Unbekanntes Backend

**Helper**:
- âœ… `test_log_backtest_metadata_with_noop`: log_backtest_metadata()

**BacktestEngine Integration**:
- âœ… `test_backtest_with_noop_tracker_no_exceptions`: Keine Exceptions
- âœ… `test_backtest_determinism_with_tracker`: Identische Ergebnisse mit/ohne Tracker
- âœ… `test_backtest_with_tracker_execution_pipeline`: ExecutionPipeline-Modus
- âœ… `test_backtest_tracker_none_works`: Backward-Compatibility (tracker=None)

### QualitÃ¤tschecks

**Linter**: âœ… Keine Fehler
```bash
ruff check src/core/tracking.py src/strategies/parameters.py \
    scripts/run_study_optuna_placeholder.py tests/test_tracking_noop.py
# â†’ No linter errors found
```

**Bestehende Tests**: âœ… Keine Regression
- Alle bestehenden Backtest-Tests laufen weiter
- Keine Breaking Changes

---

## Aktivierung & Usage

### FÃ¼r Entwickler

**1. Tracking aktivieren** (optional):

```toml
# config.toml
[tracking]
enabled = true
backend = "noop"  # oder "mlflow"
```

**2. MLflow installieren** (optional):

```bash
pip install mlflow
# oder: uv pip install mlflow
```

**3. Backtest mit Tracking**:

```python
from src.core.tracking import build_tracker_from_config
from src.backtest import BacktestEngine
from src.core.peak_config import load_config

config = load_config()
tracker = build_tracker_from_config(config)

engine = BacktestEngine(tracker=tracker)
result = engine.run_realistic(df, strategy_fn, params)

# â†’ Config + Metrics werden geloggt (wenn tracker != NoopTracker)
```

**4. MLflow UI Ã¶ffnen** (wenn MLflow installiert):

```bash
mlflow ui --backend-store-uri ./mlruns
# â†’ http://localhost:5000
```

### FÃ¼r CI/CD

**Keine Ã„nderungen nÃ¶tig**:
- Tracking ist per Default disabled
- NoopTracker ist immer verfÃ¼gbar (kein Install nÃ¶tig)
- Bestehende Pipelines funktionieren unverÃ¤ndert

### FÃ¼r Research

**Optuna-Integration (spÃ¤ter)**:

```bash
# Phase 2: Optuna installieren
pip install optuna

# Phase 3: Study Runner nutzen
python3 scripts/run_study_optuna_placeholder.py \
    --strategy ma_crossover \
    --n-trials 100
```

---

## Backward Compatibility

### Garantien

âœ… **Keine Breaking Changes**:
- `BacktestEngine()` ohne tracker funktioniert wie bisher
- `BaseStrategy` ohne `parameter_schema` funktioniert wie bisher
- Alle bestehenden Tests bleiben grÃ¼n

âœ… **Opt-In**:
- Tracking ist per Default disabled
- Parameter-Schema ist optional
- Keine neuen Required-Dependencies

âœ… **Graceful Degradation**:
- MLflow nicht installiert â†’ NoopTracker (keine Errors)
- Config fehlt â†’ NoopTracker
- Tracking-Fehler â†’ Warning, kein Crash

### Test-Beweis

```python
# Test: test_backtest_determinism_with_tracker
# Ergebnis: Identische Equity-Curves mit/ohne Tracker
assert result_without_tracker == result_with_noop_tracker
```

---

## Roadmap

### Phase 1: Foundation (âœ… Abgeschlossen)
- [x] Tracking Interface
- [x] Config Hooks
- [x] BacktestEngine Integration
- [x] Parameter Schema
- [x] Placeholder Scripts
- [x] Unit-Tests
- [x] Dokumentation

### Phase 2: MLflow Integration (ðŸ”œ Next)
- [ ] MLflowTracker vollstÃ¤ndige Implementation
- [ ] Auto-Logging fÃ¼r BacktestEngine
- [ ] Artifact Upload (Plots, Reports)
- [ ] MLflow UI Integration-Tests
- [ ] Best-Practices Dokumentation

### Phase 3: Optuna Integration (ðŸ”œ Later)
- [ ] Study Runner Implementation
- [ ] Parameter-Schema â†’ Optuna Search Space
- [ ] Multi-Objective Optimization
- [ ] Pruning-Callback
- [ ] Distributed Optimization (optional)

### Phase 4: Acceleration (â³ Future)
- [ ] Polars Backend fÃ¼r Backtests
- [ ] DuckDB fÃ¼r Multi-Symbol Queries
- [ ] Benchmarks (Pandas vs Polars)
- [ ] Incremental Data Loading

---

## Dependencies

### Core (keine neuen Hard-Dependencies)
- âœ… Nur Standard-Library + bestehende Dependencies
- âœ… `tomllib` / `tomli` (schon vorhanden)
- âœ… `pandas` (schon vorhanden)

### Optional (nicht required)
- â³ `mlflow` (fÃ¼r MLflowTracker, spÃ¤ter)
- â³ `optuna` (fÃ¼r Study Runner, spÃ¤ter)
- â³ `polars` (fÃ¼r Acceleration, viel spÃ¤ter)
- â³ `duckdb` (fÃ¼r Acceleration, viel spÃ¤ter)

**Empfehlung**: Optional Dependencies in `pyproject.toml` definieren:

```toml
[project.optional-dependencies]
research = ["mlflow>=2.10", "optuna>=3.5"]
acceleration = ["polars>=0.20", "duckdb>=0.10"]
```

---

## Known Limitations

### Aktuell (Phase 1)

1. **MLflowTracker**: Nur Stub, noch nicht vollstÃ¤ndig implementiert
   - LÃ¶sung: Phase 2 (MLflow Integration)

2. **Optuna Study Runner**: Nur Placeholder
   - LÃ¶sung: Phase 3 (Optuna Integration)

3. **Parameter Schema**: Nur 0 Strategien haben Schema definiert
   - LÃ¶sung: Schrittweise bestehende Strategien erweitern (optional)

4. **Tracking in Live**: Noch nicht implementiert
   - LÃ¶sung: Nicht geplant (Tracking nur fÃ¼r R&D, nicht fÃ¼r Live)

### Design-Entscheidungen

**"Not Now" Liste**:
- âŒ Harte ML-Integration (sklearn/torch) â†’ SpÃ¤ter, wenn Use-Case klar
- âŒ Feature Store â†’ SpÃ¤ter, wenn >100 Features
- âŒ Distributed Backtesting (Ray/Dask) â†’ SpÃ¤ter, wenn >10.000 Trials

**Grund**: Wir wollen leichtgewichtig bleiben und nur bei Bedarf erweitern.

---

## Risiken & Mitigations

### Risiko 1: MLflow als Dependency zu schwer

**Mitigation**:
- Optional Install
- Graceful Fallback zu NoopTracker
- Klare Fehlermeldungen

### Risiko 2: Tracking-Overhead in Backtests

**Mitigation**:
- NoopTracker hat nahezu keinen Overhead
- MLflow-Logging ist async (spÃ¤ter)
- Tracking nur fÃ¼r R&D, nicht fÃ¼r Live

### Risiko 3: Parameter-Schema wird nicht genutzt

**Mitigation**:
- Optional, keine Pflicht
- Klare Use-Cases in Doku (Optuna, MLflow)
- Schrittweise Migration bestehender Strategien

---

## Erfolgsmetriken

### Phase 1 (Foundation)

âœ… **Tracking Interface funktioniert**:
- 11/11 Tests bestanden
- Keine Linter-Errors
- Backward-Compatible

âœ… **Keine Performance-Regression**:
- NoopTracker hat keinen Overhead
- Bestehende Backtests laufen gleich schnell

âœ… **Dokumentation vollstÃ¤ndig**:
- 600+ Zeilen Doku
- Roadmap definiert
- Usage-Beispiele vorhanden

### Phase 2 (MLflow Integration) - Geplant

ðŸ”œ **MLflow Integration funktioniert**:
- [ ] MLflow UI zeigt Runs an
- [ ] Artifacts werden hochgeladen
- [ ] Comparison-View funktioniert

ðŸ”œ **Performance akzeptabel**:
- [ ] MLflow-Logging <100ms pro Run
- [ ] Keine Blockierung des Backtests

### Phase 3 (Optuna Integration) - Geplant

ðŸ”œ **Optuna Study lÃ¤uft**:
- [ ] Parameter-Schema â†’ Search Space funktioniert
- [ ] Trials werden zu MLflow geloggt
- [ ] Pruning funktioniert

---

## NÃ¤chste Schritte

### Sofort (User)

1. **Tracking testen**:
   ```bash
   python3 -m pytest tests/test_tracking_noop.py -v
   ```

2. **Placeholder Script testen**:
   ```bash
   python3 scripts/run_study_optuna_placeholder.py --strategy ma_crossover
   ```

3. **Doku lesen**:
   ```bash
   cat docs/STRATEGY_LAYER_VNEXT.md
   ```

### Phase 2 (MLflow Integration)

1. **MLflowTracker vollstÃ¤ndig implementieren**:
   - Lazy Import
   - Error Handling
   - Artifact Upload

2. **Integration-Tests schreiben**:
   - MLflow UI Check
   - Artifact Verification
   - Run Comparison

3. **Best-Practices Doku**:
   - MLflow Setup
   - Experiment Naming
   - Run Organization

### Phase 3 (Optuna Integration)

1. **Study Runner implementieren**:
   - Parameter-Schema auslesen
   - Optuna Objective-Function
   - MLflow Integration

2. **Multi-Objective Support**:
   - Mehrere Ziele (Sharpe, Drawdown, Win-Rate)
   - Pareto-Front Visualization

3. **Distributed Optimization** (optional):
   - Parallel Trials
   - Database Storage (sqlite â†’ postgres)

---

## Maintenance

### Code-Owner
- **Primary**: Peak_Trade Strategy Team
- **Reviewer**: Core Team (fÃ¼r Breaking Changes)

### Update-Policy
- **Tracking Interface**: Stabil (Protocol-basiert, erweiterbar)
- **Parameter Schema**: Erweiterbar (neue Typen hinzufÃ¼gen)
- **Config**: Backward-Compatible (neue Keys optional)

### Deprecation-Policy
- Keine Deprecations geplant
- Alle Features sind opt-in
- Breaking Changes nur mit Major-Version-Bump

---

## Referenzen

### Dokumentation
- **Main Doc**: `docs/STRATEGY_LAYER_VNEXT.md`
- **Tracking**: `src/core/tracking.py` (Docstrings)
- **Parameter Schema**: `src/strategies/parameters.py` (Docstrings)

### Code
- **Tracking Interface**: `src/core/tracking.py`
- **BacktestEngine**: `src/backtest/engine.py`
- **Parameter Schema**: `src/strategies/parameters.py`
- **Tests**: `tests/test_tracking_noop.py`

### Related ADRs
- `ADR_0001_Peak_Tool_Stack.md` (Tool-Auswahl)

---

## Changelog

### 2025-12-23: Phase 1 Complete

**Added**:
- âœ… Tracking Interface (Protocol, NoopTracker, MLflowTracker-Stub)
- âœ… Config Hooks (`[tracking]` in default.toml)
- âœ… BacktestEngine Integration (optional tracker parameter)
- âœ… Parameter Schema (`src/strategies/parameters.py`)
- âœ… Placeholder Scripts (`run_study_optuna_placeholder.py`)
- âœ… Unit-Tests (11 Tests, alle bestanden)
- âœ… Dokumentation (`docs/STRATEGY_LAYER_VNEXT.md`)

**Changed**:
- âœ… `src/core/__init__.py`: Tracking-Exports
- âœ… `src/backtest/engine.py`: Tracker-Parameter + Logging
- âœ… `config/default.toml`: `[tracking]` Sektion

**No Breaking Changes**: Alle bestehenden Tests grÃ¼n âœ…

---

## Fazit

Phase 1 "Foundation" ist erfolgreich abgeschlossen. Wir haben:

1. âœ… **Tooling Hooks vorbereitet** fÃ¼r MLflow/Optuna/Polars/DuckDB
2. âœ… **Keine Breaking Changes** eingefÃ¼hrt (Backward-Compatible)
3. âœ… **Opt-In Design** implementiert (Tracking disabled per Default)
4. âœ… **Tests geschrieben** (11/11 bestanden, keine Regression)
5. âœ… **Dokumentation erstellt** (600+ Zeilen, vollstÃ¤ndig)

**Ready for Phase 2**: MLflow Integration kann beginnen ðŸš€

---

**Maintainer**: Peak_Trade Team  
**Last Updated**: 2025-12-23  
**Status**: âœ… Phase 1 Complete
