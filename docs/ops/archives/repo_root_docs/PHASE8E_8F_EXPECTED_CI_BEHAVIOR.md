# Phase 8E/8F â€“ Expected CI Behavior

**Version:** 1.0  
**Date:** 2026-01-04  
**Workflow:** `.github/workflows/var_report_regression_gate.yml`

---

## ğŸ“Š Exit Codes

### Commands

| Command | Success | Failure | Notes |
|---------|---------|---------|-------|
| `pytest tests&#47;risk&#47;validation&#47;test_report_compare.py` | 0 | â‰ 0 | 12 tests must pass |
| `pytest tests&#47;risk&#47;validation&#47;test_report_index.py` | 0 | â‰ 0 | 10 tests must pass |
| `python3 scripts&#47;risk&#47;var_suite_compare_runs.py ...` | 0 | â‰ 0 | Script execution (warns if regressions found) |
| `python3 scripts&#47;risk&#47;var_suite_build_index.py ...` | 0 | â‰ 0 | Script execution |
| Verify compare outputs exist | 0 | 1 | Check for `compare.{json,md,html}` |
| Verify index outputs exist | 0 | 1 | Check for `index.{json,md,html}` |
| Verify JSON validity | 0 | 1 | `json.load()` must succeed |
| Verify deterministic sorting | 0 | 1 | Run IDs must be sorted alphabetically |

---

## ğŸš¦ Gate Logic

```python
def ci_gate_logic():
    """Pseudo-code for CI gate decision."""

    # Step 1: Run Tests
    if pytest_report_compare() != 0:
        return FAIL  # Exit 1

    if pytest_report_index() != 0:
        return FAIL  # Exit 1

    # Step 2: Run Compare (with fixtures)
    if run_compare_script() != 0:
        return FAIL  # Exit 1

    if not compare_outputs_exist():
        return FAIL  # Exit 1

    if not compare_json_valid():
        return FAIL  # Exit 1

    # Step 3: Run Index (with fixtures)
    if run_index_script() != 0:
        return FAIL  # Exit 1

    if not index_outputs_exist():
        return FAIL  # Exit 1

    if not index_json_valid():
        return FAIL  # Exit 1

    if not index_run_ids_sorted():
        return FAIL  # Exit 1

    # Step 4: All checks passed
    return PASS  # Exit 0
```

---

## âœ… Success Criteria

Gate **PASSES** when:

1. âœ… All `test_report_compare.py` tests pass (12/12)
2. âœ… All `test_report_index.py` tests pass (10/10)
3. âœ… Compare script executes without errors
4. âœ… Compare outputs exist: `compare.{json,md,html}`
5. âœ… `compare.json` is valid JSON
6. âœ… Index script executes without errors
7. âœ… Index outputs exist: `index.{json,md,html}`
8. âœ… `index.json` is valid JSON
9. âœ… Run IDs in `index.json` are sorted alphabetically (deterministic)
10. âœ… CLI smoke tests pass (help commands)

**Result:** Gate exits with code **0**

---

## âŒ Failure Scenarios

Gate **FAILS** when:

### Scenario 1: Test Failures
- âŒ Any test in `test_report_compare.py` fails
- âŒ Any test in `test_report_index.py` fails
- **Exit Code:** â‰ 0 from pytest
- **CI Status:** âŒ Failed

### Scenario 2: Script Errors
- âŒ `var_suite_compare_runs.py` exits with error (e.g., baseline not found)
- âŒ `var_suite_build_index.py` exits with error (e.g., report-root not found)
- **Exit Code:** â‰ 0 from script
- **CI Status:** âŒ Failed

### Scenario 3: Output Missing
- âŒ `compare.json` not created
- âŒ `compare.md` not created
- âŒ `compare.html` not created
- âŒ `index.json` not created
- âŒ `index.md` not created
- âŒ `index.html` not created
- **Exit Code:** 1 from verification step
- **CI Status:** âŒ Failed

### Scenario 4: Invalid JSON
- âŒ `compare.json` is not valid JSON (syntax error)
- âŒ `index.json` is not valid JSON (syntax error)
- **Exit Code:** 1 from `python3 -c "import json; json.load(...)"`
- **CI Status:** âŒ Failed

### Scenario 5: Non-Deterministic Output
- âŒ Run IDs in `index.json` are not sorted alphabetically
- **Exit Code:** 1 from sorting verification
- **CI Status:** âŒ Failed

### Scenario 6: CLI Smoke Test Failure
- âŒ `var_suite_compare_runs.py --help` fails
- âŒ `var_suite_build_index.py --help` fails
- **Exit Code:** â‰ 0 from CLI command
- **CI Status:** âŒ Failed

---

## ğŸ” Debugging Failed Gates

### Check 1: Test Logs

```bash
# View test output in CI logs
# Look for:
# - "FAILED tests/risk/validation/test_report_compare.py::test_name"
# - "AssertionError: ..."
# - "FileNotFoundError: ..."
```

### Check 2: Script Output

```bash
# View script output in CI logs
# Look for:
# - "ERROR: Baseline run not found"
# - "ERROR: compare.json not generated"
# - Traceback
```

### Check 3: Verification Logs

```bash
# View verification output in CI logs
# Look for:
# - "âŒ ERROR: compare.json not generated"
# - "Traceback (most recent call last):"
# - "AssertionError: Run IDs not sorted"
```

### Check 4: Artifacts

```bash
# Download artifacts from failed run
# - var-report-compare-<run_number>.zip
# - Contains: compare.json, compare.md, compare.html
# - Inspect for anomalies
```

---

## ğŸ¯ Expected Outputs

### Compare Outputs

```
reports/var_suite/ci_compare/
â”œâ”€â”€ compare.json      (1-2 KB, valid JSON)
â”œâ”€â”€ compare.md        (500-1000 bytes, markdown)
â””â”€â”€ compare.html      (4-5 KB, HTML with CSS)
```

### Index Outputs

```
tests/fixtures/var_suite_reports/
â”œâ”€â”€ index.json        (1-2 KB, valid JSON)
â”œâ”€â”€ index.md          (500-1000 bytes, markdown)
â””â”€â”€ index.html        (4-5 KB, HTML with CSS)
```

---

## ğŸ“ˆ Performance Expectations

| Step | Expected Duration | Timeout |
|------|-------------------|---------|
| Checkout | ~5s | 1 min |
| Setup Python | ~10s | 2 min |
| Install dependencies | ~30s | 5 min |
| Test `report_compare` | ~2s | 1 min |
| Test `report_index` | ~1s | 1 min |
| Compare gate | ~1s | 1 min |
| Index gate | ~1s | 1 min |
| Upload artifacts | ~5s | 2 min |
| **Total** | **~55s** | **10 min** |

---

## ğŸ”” Notification Strategy

### On Success
- âœ… Green checkmark in PR
- âœ… No notifications
- âœ… Artifacts available for download (30 days)

### On Failure
- âŒ Red X in PR
- âŒ Email notification to PR author
- âŒ Comment on PR with failure reason (optional)
- âŒ Artifacts available for debugging

---

## ğŸ›¡ï¸ Safety Guarantees

### What This Gate Validates

âœ… **Correctness:**
- âœ… report_compare logic (12 tests)
- âœ… report_index logic (10 tests)
- âœ… CLI entry points (smoke tests)
- âœ… Deterministic output (sorting, formatting)

âœ… **Compatibility:**
- âœ… Fixtures remain valid
- âœ… JSON schema stability
- âœ… Output file generation

âœ… **Regression Detection:**
- âœ… Changes that break tests â†’ Gate FAILS
- âœ… Changes that break CLI â†’ Gate FAILS
- âœ… Changes that break determinism â†’ Gate FAILS

### What This Gate Does NOT Validate

âŒ **Out of Scope:**
- âŒ VaR calculation correctness (separate tests)
- âŒ Risk validation logic (separate tests)
- âŒ Live trading behavior (not applicable)
- âŒ Performance benchmarks (not implemented)
- âŒ Semantic regressions in reports (requires human review)

---

## ğŸ“ Example CI Run

### Successful Run

```
âœ… Checkout repository
âœ… Set up Python 3.11
âœ… Install dependencies
âœ… Run report_compare tests (12 passed)
âœ… Run report_index tests (10 passed)
âœ… Run deterministic compare gate
   âœ“ All comparison files generated successfully
   âœ“ compare.json is valid JSON
âœ… Run deterministic index gate
   âœ“ All index files generated successfully
   âœ“ index.json is valid JSON
   âœ“ Run IDs are deterministically sorted
   âœ“ Cleaned up generated index files
âœ… Upload comparison artifacts
âœ… Smoke: var_suite_compare_runs.py --help
âœ… Smoke: var_suite_build_index.py --help
âœ… VaR Report Gate Summary
   âœ… Gate PASSED
```

**Exit Code:** 0  
**CI Status:** âœ… Passed

---

### Failed Run (Example: Test Failure)

```
âœ… Checkout repository
âœ… Set up Python 3.11
âœ… Install dependencies
âŒ Run report_compare tests
   FAILED tests/risk/validation/test_report_compare.py::test_deterministic_output
   AssertionError: Output not deterministic
âŒ VaR Report Gate Summary
   âŒ Gate FAILED
```

**Exit Code:** 1  
**CI Status:** âŒ Failed

---

## ğŸ”— Related

- **Workflow:** `.github/workflows/var_report_regression_gate.yml`
- **Runbook:** `docs/ops/runbooks/var_report_compare.md`
- **PR:** `PHASE8E_8F_CI_INTEGRATION_PR.md`
- **Tests:** `tests&#47;risk&#47;validation&#47;test_report_*.py`

---

**Version History:**
- **v1.0** (2026-01-04) â€” Initial version
