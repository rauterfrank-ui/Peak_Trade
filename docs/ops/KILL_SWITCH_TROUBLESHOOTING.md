# Peak_Trade Kill Switch ‚Äì Troubleshooting Guide

**Version:** 1.0  
**Datum:** 2025-12-28  
**F√ºr:** Operations Team & Engineers

---

## üéØ √úbersicht

Dieser Guide hilft bei der Diagnose und L√∂sung von Problemen mit dem Emergency Kill Switch.

**Bei akuten Problemen:** Siehe [KILL_SWITCH_RUNBOOK.md](KILL_SWITCH_RUNBOOK.md) f√ºr Standard-Operationen.

---

## üîç Diagnose-Checkliste

### Quick Health Check

```bash
# 1. Kill Switch Status
./scripts/ops/kill_switch_ctl.sh status

# 2. Logs pr√ºfen
tail -f logs/kill_switch.log

# 3. State File pr√ºfen
cat data/kill_switch/state.json

# 4. Audit Trail
./scripts/ops/kill_switch_ctl.sh audit --limit 10
```

---

## ‚ùå Problem: Kill Switch l√§sst sich nicht triggern

### Symptom
```
‚ùå Failed to trigger (already killed or disabled)
```

### Diagnose

**Schritt 1: Status pr√ºfen**
```bash
./scripts/ops/kill_switch_ctl.sh status
```

**M√∂gliche Ursachen:**

#### A) Bereits im KILLED State
**Erkennung:** Status zeigt üî¥ KILLED

**L√∂sung:** Bereits getriggert, kein Handlungsbedarf
```bash
# Status best√§tigen
./scripts/ops/kill_switch_ctl.sh status

# Falls n√∂tig: Recovery
./scripts/ops/kill_switch_ctl.sh recover
```

#### B) Kill Switch DISABLED (Backtest Mode)
**Erkennung:** Status zeigt ‚ö™ DISABLED oder Fehlermeldung

**Diagnose:**
```bash
# Config pr√ºfen
grep "mode" config/risk/kill_switch.toml
# Output: mode = "disabled"
```

**L√∂sung:**
```toml
# config/risk/kill_switch.toml
[kill_switch]
mode = "active"  # √Ñndern von "disabled" zu "active"
```

**Nach √Ñnderung:** System neustarten

#### C) Permissions-Problem
**Diagnose:**
```bash
ls -la scripts/ops/kill_switch_ctl.sh
# Sollte: -rwxr-xr-x (executable)
```

**L√∂sung:**
```bash
chmod +x scripts/ops/kill_switch_ctl.sh
```

---

## ‚ùå Problem: Recovery funktioniert nicht

### Symptom
```
‚ùå Recovery request failed
Possible reasons:
  - Not in KILLED state
  - Invalid approval code
```

### Diagnose

**Schritt 1: Aktuellen State pr√ºfen**
```bash
./scripts/ops/kill_switch_ctl.sh status
```

### M√∂gliche Ursachen

#### A) Nicht im KILLED State
**Erkennung:** State ist ACTIVE oder RECOVERING

**Erkl√§rung:** Recovery nur von KILLED ‚Üí RECOVERING m√∂glich

**L√∂sung:**
- Falls ACTIVE: Kein Recovery n√∂tig
- Falls RECOVERING: Warten bis Cooldown abgelaufen

#### B) Falscher Approval Code
**Diagnose:**
```bash
# Approval Code in Environment pr√ºfen
echo $KILL_SWITCH_APPROVAL_CODE
# Output: (leer oder falsch)
```

**L√∂sung:**
```bash
# Korrekten Code setzen
export KILL_SWITCH_APPROVAL_CODE='correct_code_here'

# Aus .env File laden (falls vorhanden)
source .env

# Recovery erneut versuchen
./scripts/ops/kill_switch_ctl.sh recover
```

#### C) Approval Code fehlt komplett
**Erkennung:** `KILL_SWITCH_APPROVAL_CODE` ist nicht gesetzt

**L√∂sung:**
```bash
# 1. Code vom Team-Lead erhalten
# 2. In Environment setzen
export KILL_SWITCH_APPROVAL_CODE='team_provided_code'

# 3. Oder in .env File speichern (f√ºr permanente Verf√ºgbarkeit)
echo "KILL_SWITCH_APPROVAL_CODE='team_provided_code'" >> .env
source .env
```

#### D) Cooldown noch aktiv
**Erkennung:** Status zeigt "Cooldown: XXs remaining"

**Erkl√§rung:** Cooldown von 5 Minuten nach Recovery-Request

**L√∂sung:** Warten bis Cooldown abgelaufen
```bash
# Cooldown √ºberwachen
watch -n 10 './scripts/ops/kill_switch_ctl.sh status'
```

---

## ‚ùå Problem: Health Check schl√§gt fehl

### Symptom
```
‚ùå HEALTH CHECK FAILED
   2 passed, 2 failed

Issues:
   - Insufficient memory: 384MB < 512MB
   - Exchange not connected
```

### Diagnose nach Problem-Typ

#### A) Memory-Problem
**Symptom:** "Insufficient memory: XXXMB < 512MB"

**Diagnose:**
```bash
# 1. Speicher-Verbrauch pr√ºfen
free -m

# 2. Top Memory-Consumer finden
ps aux --sort=-%mem | head -10

# 3. Kill Switch Schwellwert pr√ºfen
grep "min_memory_available_mb" config/risk/kill_switch.toml
```

**L√∂sungen:**

**Option 1: Speicher freigeben**
```bash
# Unn√∂tige Prozesse beenden
kill <PID>

# Cache leeren (vorsichtig!)
sync; echo 3 > /proc/sys/vm/drop_caches  # Nur als root
```

**Option 2: Schwellwert anpassen** (tempor√§r f√ºr Recovery)
```toml
# config/risk/kill_switch.toml
[kill_switch.recovery]
min_memory_available_mb = 256  # Reduzieren (nur tempor√§r!)
```

**Option 3: System neustarten**
```bash
sudo reboot
```

#### B) CPU-Problem
**Symptom:** "High CPU usage: XX% > 80%"

**Diagnose:**
```bash
# CPU-intensive Prozesse finden
top -o %CPU

# Load Average pr√ºfen
uptime
```

**L√∂sungen:**

**Option 1: CPU-intensive Prozesse beenden**
```bash
# Identifizieren und beenden
kill <PID>
```

**Option 2: Warten**
- Falls tempor√§re Spitze: 5-10 Minuten warten
- Dann Health Check erneut

**Option 3: Schwellwert anpassen** (tempor√§r)
```toml
[kill_switch.recovery]
max_cpu_percent = 95  # Erh√∂hen (nur tempor√§r!)
```

#### C) Exchange-Verbindung
**Symptom:** "Exchange not connected"

**Diagnose:**
```bash
# 1. Netzwerk-Verbindung testen
ping api.kraken.com

# 2. Exchange-Status pr√ºfen (externe API)
curl https://status.kraken.com/api/v2/status.json | jq

# 3. Eigene Exchange-Connection pr√ºfen
# (Je nach System - ggf. in Logs schauen)
tail -f logs/exchange.log
```

**L√∂sungen:**

**Option 1: Verbindung wiederherstellen**
```bash
# Data Pipeline neustarten
./scripts/data/restart_pipeline.sh

# Oder gesamtes System
./scripts/ops/restart_all.sh
```

**Option 2: Exchange-Check deaktivieren** (nur f√ºr Recovery!)
```toml
# config/risk/kill_switch.toml
[kill_switch.recovery]
require_exchange_connection = false  # Tempor√§r!
```

**Wichtig:** Nach erfolgreicher Recovery wieder aktivieren!

#### D) Stale Price Data
**Symptom:** "Stale price data (XXXs old)"

**Diagnose:**
```bash
# 1. Data Pipeline Status
./scripts/data/pipeline_status.sh

# 2. Letzte Price Updates pr√ºfen
tail -f logs/data_pipeline.log | grep "price"

# 3. Exchange API Rate Limits pr√ºfen
grep "rate_limit" logs/exchange.log
```

**L√∂sungen:**

**Option 1: Data Pipeline neustarten**
```bash
./scripts/data/restart_pipeline.sh
```

**Option 2: Exchange API-Key pr√ºfen**
```bash
# Pr√ºfe ob API-Key noch g√ºltig
echo $KRAKEN_API_KEY  # Sollte gesetzt sein
```

**Option 3: Price Feed Check deaktivieren** (tempor√§r)
```toml
[kill_switch.recovery]
require_price_feed = false  # Tempor√§r!
```

---

## ‚ùå Problem: Gradual Restart funktioniert nicht

### Symptom
Position Limits bleiben bei 50% stecken

### Diagnose

**Schritt 1: Recovery Status pr√ºfen**
```bash
./scripts/ops/kill_switch_ctl.sh status
```

**Schritt 2: Verstrichene Zeit pr√ºfen**
```python
# Im Python-Interpreter oder Script:
from src.risk_layer.kill_switch.recovery import RecoveryManager
manager = RecoveryManager(config, health_checker)
print(f"Current factor: {manager.position_limit_factor}")
print(f"Stage: {manager.current_stage}")
```

### L√∂sungen

#### Option 1: Warten
- Initial: 50% Position Limits
- Nach 1h: 75% Position Limits
- Nach 2h: 100% Position Limits

**Monitoring:**
```bash
# Position Limit Factor √ºberwachen
watch -n 300 'echo "Factor: $(date)"'  # Alle 5 Minuten
```

#### Option 2: Config anpassen
**F√ºr zuk√ºnftige Recoveries:**
```toml
# config/risk/kill_switch.toml
[kill_switch.recovery]
escalation_intervals = [1800, 3600]  # 30min, 1h statt 1h, 2h
```

#### Option 3: Gradual Restart deaktivieren
**Nur in Notf√§llen:**
```toml
[kill_switch.recovery]
gradual_restart_enabled = false  # Direkt auf 100%
```

**Wichtig:** System neustarten nach Config-√Ñnderung!

---

## ‚ùå Problem: State File korrupt

### Symptom
```
ERROR: Corrupt state file
```

### Diagnose

**Schritt 1: State File pr√ºfen**
```bash
# Versuche State File zu lesen
cat data/kill_switch/state.json

# Pr√ºfe auf valides JSON
jq . data/kill_switch/state.json
```

**Schritt 2: Backups pr√ºfen**
```bash
ls -lh data/kill_switch/backups/
```

### L√∂sungen

#### Option 1: Restore from Backup
```python
from src.risk_layer.kill_switch.persistence import StatePersistence

persistence = StatePersistence("data/kill_switch/state.json")

# Liste Backups
backups = persistence.list_backups()
print(f"Available backups: {len(backups)}")

# Restore from latest
persistence.restore_from_backup()
```

**Oder via Bash:**
```bash
# Manuell neuestes Backup kopieren
cp data/kill_switch/backups/state_*.json data/kill_switch/state.json
```

#### Option 2: State neu initialisieren
```python
from src.risk_layer.kill_switch import KillSwitch, load_config

config = load_config()
kill_switch = KillSwitch(config.get("kill_switch", {}))

# State ist jetzt ACTIVE (initial state)
```

**Oder State File l√∂schen:**
```bash
# L√∂schen (System startet mit ACTIVE)
rm data/kill_switch/state.json

# System neu starten
./scripts/ops/restart_trading.sh
```

---

## ‚ùå Problem: Audit Trail nicht lesbar

### Symptom
- Audit-Befehle liefern keine oder falsche Daten
- Fehler beim Lesen von Audit Files

### Diagnose

**Schritt 1: Audit Dateien pr√ºfen**
```bash
# Liste Audit Files
ls -lh data/kill_switch/audit/

# Pr√ºfe neueste Datei
tail -5 data/kill_switch/audit/kill_switch_audit_*.jsonl

# Versuche JSONL zu parsen
head -1 data/kill_switch/audit/kill_switch_audit_*.jsonl | jq
```

### L√∂sungen

#### Problem: Permissions
```bash
# Pr√ºfe Permissions
ls -la data/kill_switch/audit/

# Falls n√∂tig: Korrigieren
chmod 644 data/kill_switch/audit/*.jsonl
```

#### Problem: Korrupte Zeilen
**Erkl√§rung:** Einzelne korrupte Zeilen werden automatisch √ºbersprungen

**Manuelle Bereinigung (falls n√∂tig):**
```bash
# Pr√ºfe auf korrupte Zeilen
for file in data/kill_switch/audit/*.jsonl; do
    echo "Checking $file..."
    while IFS= read -r line; do
        echo "$line" | jq . > /dev/null 2>&1 || echo "Corrupt: $line"
    done < "$file"
done
```

#### Problem: Compression-Fehler
```bash
# Test compressed files
for file in data/kill_switch/audit/*.jsonl.gz; do
    echo "Testing $file..."
    zcat "$file" | head -1 | jq
done

# Falls korrupt: Neu komprimieren
gunzip data/kill_switch/audit/corrupt_file.jsonl.gz
gzip data/kill_switch/audit/corrupt_file.jsonl
```

---

## ‚ùå Problem: CLI funktioniert nicht

### Symptom
```
pyenv: python: command not found
```

### Diagnose

**Python-Version pr√ºfen:**
```bash
# Python verf√ºgbar?
which python
which python3

# Version pr√ºfen
python --version
python3 --version
```

### L√∂sungen

#### Option 1: Python Alias setzen
```bash
alias python=python3
```

#### Option 2: Direkter Python3-Aufruf
```bash
python3 -m src.risk_layer.kill_switch.cli status
```

#### Option 3: Ops Script nutzen (bevorzugt)
```bash
# Script erkennt automatisch python3
./scripts/ops/kill_switch_ctl.sh status
```

---

## üîÑ Problem: System h√§ngt im RECOVERING State

### Symptom
- State ist RECOVERING seit > 10 Minuten
- Cooldown scheint nicht abzulaufen

### Diagnose

```bash
# Status mit Cooldown-Info
./scripts/ops/kill_switch_ctl.sh status

# State File pr√ºfen
cat data/kill_switch/state.json | jq .
```

### L√∂sungen

#### Option 1: Cooldown-Zeit abwarten
**Standard Cooldown:** 5 Minuten

```bash
# Warten und Status √ºberwachen
watch -n 30 './scripts/ops/kill_switch_ctl.sh status'
```

#### Option 2: Complete Recovery manuell triggern
```python
from src.risk_layer.kill_switch import KillSwitch, load_config

config = load_config()
ks = KillSwitch(config.get("kill_switch", {}))

# Force complete recovery (nach Cooldown)
result = ks.complete_recovery()
print(f"Recovery complete: {result}")
```

#### Option 3: State manuell zur√ºcksetzen (NOTFALL)
**Nur in Extremf√§llen!**

```bash
# 1. Backup erstellen
cp data/kill_switch/state.json data/kill_switch/state_backup_manual.json

# 2. State l√∂schen
rm data/kill_switch/state.json

# 3. System neustarten
# System startet mit ACTIVE State
```

---

## üìä Logging & Debugging

### Log-Level erh√∂hen

```toml
# config/risk/kill_switch.toml
[kill_switch]
log_level = "DEBUG"  # Von INFO auf DEBUG
```

### Logs Analysieren

```bash
# Kill Switch Logs
tail -f logs/kill_switch.log

# Fehler finden
grep "ERROR" logs/kill_switch.log

# Trigger Events
grep "TRIGGERED" logs/kill_switch.log

# State Changes
grep "State:" logs/kill_switch.log
```

### Debug-Modus

```python
# In Python-Console oder Script:
import logging
logging.basicConfig(level=logging.DEBUG)

from src.risk_layer.kill_switch import KillSwitch
# ... debug operations
```

---

## üÜò Eskalation

### Wann eskalieren?

Eskaliere an Engineering Team wenn:
- ‚ùå Kill Switch l√§sst sich nicht aktivieren/deaktivieren
- ‚ùå State Machine h√§ngt
- ‚ùå Health Checks schlagen dauerhaft fehl
- ‚ùå Unerwartetes Verhalten (State Transitions)
- ‚ùå Data Corruption (State/Audit Files)
- ‚ùå System startet nicht nach Recovery

### Informationen sammeln

**Vor Eskalation:**
```bash
# 1. Status exportieren
./scripts/ops/kill_switch_ctl.sh status > /tmp/ks_status.txt

# 2. Audit Trail
./scripts/ops/kill_switch_ctl.sh audit --since 24h > /tmp/ks_audit.txt

# 3. Logs
tail -n 1000 logs/kill_switch.log > /tmp/ks_logs.txt

# 4. Health Check
./scripts/ops/kill_switch_ctl.sh health > /tmp/ks_health.txt

# 5. Config
cat config/risk/kill_switch.toml > /tmp/ks_config.toml

# 6. State Files
cat data/kill_switch/state.json > /tmp/ks_state.json

# Alle Dateien archivieren
tar -czf kill_switch_debug_$(date +%Y%m%d_%H%M%S).tar.gz /tmp/ks_*
```

### Kontakte

**Engineering On-Call:** [Nummer eintragen]  
**Slack:** `#peak-trade-ops`  
**Email:** ops@peak-trade.com

---

## üìö Weitere Ressourcen

- **Runbook:** [KILL_SWITCH_RUNBOOK.md](KILL_SWITCH_RUNBOOK.md)
- **Tech Docs:** [../risk/KILL_SWITCH.md](../risk/KILL_SWITCH.md)
- **Architecture:** [../risk/KILL_SWITCH_ARCHITECTURE.md](../risk/KILL_SWITCH_ARCHITECTURE.md)

---

**Letzte Aktualisierung:** 2025-12-28  
**Version:** 1.0  
**Maintainer:** Peak_Trade Ops Team
