# Peak_Trade Kill Switch â€“ Operator Runbook

**Version:** 1.0  
**Datum:** 2025-12-28  
**FÃ¼r:** Operations Team

---

## ğŸ¯ Ãœbersicht

Dieses Runbook beschreibt die operativen Verfahren fÃ¼r den Emergency Kill Switch.

**Was ist der Kill Switch?**
- **Layer 4** der Risk Management Defense-in-Depth Architektur
- **Letzte Verteidigungslinie** gegen unkontrollierte Trading-Verluste
- **Blockt alle Trading-AktivitÃ¤ten** sofort bei Aktivierung

**Wann aktivieren?**
- Portfolio Drawdown > 15%
- Unerwartetes Systemverhalten
- VerdÃ¤chtige Marktbedingungen
- System-Anomalien (Memory/CPU)
- Exchange-Verbindungsprobleme
- Geplante Wartungsarbeiten

---

## ğŸš¨ NOTFALL-VERFAHREN

### 1. MANUELLER KILL SWITCH TRIGGER

**Wann:** Sofortige Notabschaltung erforderlich

**Schritte:**

```bash
# 1. Terminal Ã¶ffnen
cd ~/Peak_Trade

# 2. Virtual Environment aktivieren
source venv/bin/activate
# oder
source .venv/bin/activate

# 3. Kill Switch triggern
./scripts/ops/kill_switch_ctl.sh trigger "GRUND FÃœR NOTABSCHALTUNG"

# Alternative: Direkt via Python CLI
python3 -m src.risk_layer.kill_switch.cli trigger \
  --reason "Grund hier eintragen" \
  --confirm
```

**BestÃ¤tigung:**
- System fragt nach BestÃ¤tigung: Tippe `yes`
- Ausgabe: `ğŸš¨ KILL SWITCH TRIGGERED`
- Trading ist **sofort blockiert**

**Wichtig:**
- Dokumentiere den Grund ausfÃ¼hrlich!
- Informiere das Team (Slack/Email)
- Beginne mit Ursachenanalyse

---

### 2. STATUS PRÃœFEN

**Zweck:** Aktuellen Zustand des Kill Switch Ã¼berprÃ¼fen

```bash
# Via Operator Script
./scripts/ops/kill_switch_ctl.sh status

# Via Python CLI
python3 -m src.risk_layer.kill_switch.cli status
```

**Ausgabe-Interpretation:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ KILL SWITCH STATUS                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ State:         ğŸŸ¢ ACTIVE               â”‚   â† Trading erlaubt
â”‚ Last Trigger:  Never                   â”‚
â”‚ Events:        0                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Status-Symbole:**
- ğŸŸ¢ **ACTIVE**: Normal-Betrieb, Trading erlaubt
- ğŸ”´ **KILLED**: Notfall-Stopp aktiv, Trading blockiert
- ğŸŸ¡ **RECOVERING**: Recovery-Phase, Trading noch blockiert
- âšª **DISABLED**: Deaktiviert (nur Backtest-Mode)

---

### 3. RECOVERY-PROZESS

**Voraussetzungen:**
- âœ… Trigger-Ursache behoben
- âœ… System Health OK
- âœ… Team informiert
- âœ… Approval Code verfÃ¼gbar

**Schritt 1: Approval Code setzen**

```bash
# Approval Code als Umgebungsvariable setzen
export KILL_SWITCH_APPROVAL_CODE='dein_code_hier'

# Code aus .env Datei laden (falls vorhanden)
source .env
```

**Schritt 2: Health Check durchfÃ¼hren**

```bash
./scripts/ops/kill_switch_ctl.sh health
```

Erwartete Ausgabe bei gesundem System:
```
âœ… HEALTH CHECK PASSED
   4 checks passed

Details:
   memory_available_mb: 2048
   cpu_percent: 45.2
   exchange_connected: True
   price_data_age_seconds: 5
```

**Schritt 3: Recovery starten**

```bash
./scripts/ops/kill_switch_ctl.sh recover
```

Das Script fragt nach:
1. **Reason for recovery**: Kurze Beschreibung (z.B. "Issue behoben, System stabil")
2. Verwendet automatisch `KILL_SWITCH_APPROVAL_CODE` aus Environment

**Erwartete Ausgabe:**
```
â³ RECOVERY STARTED
Reason: Issue behoben, System stabil
Cooldown active. Use 'status' to check progress.

Next steps:
  1. Wait for cooldown period (5 minutes)
  2. Monitor status: kill_switch_ctl.sh status
  3. System will gradually restart with reduced position limits
```

**Schritt 4: Cooldown abwarten**

```bash
# Status regelmÃ¤ÃŸig prÃ¼fen
watch -n 10 './scripts/ops/kill_switch_ctl.sh status'
```

Nach **5 Minuten** wechselt Status automatisch zu ACTIVE.

**Schritt 5: Gradual Restart Ã¼berwachen**

Nach Recovery startet das System mit **reduzierten Position Limits**:

| Zeit nach Recovery | Position Limit | Beschreibung |
|-------------------|----------------|--------------|
| 0 - 1h | 50% | Vorsichtiger Start |
| 1h - 2h | 75% | ErhÃ¶hte Limits |
| 2h+ | 100% | VollstÃ¤ndig recovered |

**Monitoring:**
```bash
# Logs Ã¼berwachen
tail -f logs/kill_switch.log

# Trading-AktivitÃ¤t prÃ¼fen
./scripts/ops/ops_center.sh monitor
```

---

## ğŸ“Š AUDIT TRAIL

### Audit-Events anzeigen

```bash
# Letzte 20 Events
./scripts/ops/kill_switch_ctl.sh audit

# Events der letzten 24 Stunden
./scripts/ops/kill_switch_ctl.sh audit --since 24h

# Events der letzten 7 Tage
./scripts/ops/kill_switch_ctl.sh audit --since 7d

# Spezifisches Datum
python3 -m src.risk_layer.kill_switch.cli audit \
  --since "2025-12-20" \
  --limit 100
```

**Ausgabe-Format:**
```
ğŸ“‹ AUDIT TRAIL (10 events)

Timestamp            Previous     New State    Triggered By    Reason
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
2025-12-28 14:32:15  ACTIVE       KILLED       manual_cli      Maintenance required
2025-12-28 14:37:20  KILLED       RECOVERING   manual          Recovery requested by operator
2025-12-28 14:42:25  RECOVERING   ACTIVE       system          Recovery completed
```

### Audit-Dateien

**Speicherort:** `data&#47;kill_switch&#47;audit&#47;`

**Format:** JSONL (JSON Lines) - eine Zeile pro Event

**Rotation:**
- Daily (neue Datei jeden Tag)
- Size-based (max 10 MB pro Datei)

**Retention:** 90 Tage

**Manuelle Analyse:**
```bash
# Alle Events anzeigen
cat data/kill_switch/audit/kill_switch_audit_2025-12-28.jsonl | jq

# Nach State filtern
grep '"new_state":"KILLED"' data/kill_switch/audit/*.jsonl

# Komprimierte Logs lesen
zcat data/kill_switch/audit/kill_switch_audit_2025-12-20.jsonl.gz | jq
```

---

## ğŸ¥ HEALTH CHECKS

### System Health prÃ¼fen

```bash
./scripts/ops/kill_switch_ctl.sh health
```

**GeprÃ¼fte Komponenten:**

1. **Memory**: VerfÃ¼gbarer RAM
   - Minimum: 512 MB
   - Kritisch bei: <512 MB

2. **CPU**: CPU-Auslastung
   - Maximum: 80%
   - Kritisch bei: >80%

3. **Exchange Connection**: Verbindung zur BÃ¶rse
   - Erforderlich: `True`
   - Kritisch bei: `False`

4. **Price Feed**: AktualitÃ¤t der Kursdaten
   - Maximum Alter: 5 Minuten
   - Kritisch bei: >5 Minuten

**Fehlerbehandlung:**

Wenn Health Check fehlschlÃ¤gt:
```
âŒ HEALTH CHECK FAILED
   2 passed, 2 failed

Issues:
   - Insufficient memory: 384MB < 512MB
   - Exchange not connected
```

**MaÃŸnahmen:**
1. Identifiziere das Problem
2. Behebe die Ursache
3. Wiederhole Health Check
4. Erst danach Recovery starten

---

## ğŸ”§ TROUBLESHOOTING

### Problem: Kill Switch lÃ¤sst sich nicht triggern

**Symptome:**
```
âŒ Failed to trigger (already killed or disabled)
```

**Ursachen & LÃ¶sungen:**

1. **Bereits im KILLED State**
   - PrÃ¼fen: `./scripts/ops/kill_switch_ctl.sh status`
   - LÃ¶sung: Ist bereits getriggert, kein Handlungsbedarf

2. **Kill Switch DISABLED (Backtest Mode)**
   - PrÃ¼fen: `config/risk/kill_switch.toml` â†’ `mode = "disabled"`
   - LÃ¶sung: Setze `mode = "active"` und restarte System

3. **Keine Permissions**
   - PrÃ¼fen: `ls -la scripts/ops/kill_switch_ctl.sh`
   - LÃ¶sung: `chmod +x scripts&#47;ops&#47;kill_switch_ctl.sh`

---

### Problem: Recovery funktioniert nicht

**Symptome:**
```
âŒ Recovery request failed
Possible reasons:
  - Not in KILLED state
  - Invalid approval code
```

**Ursachen & LÃ¶sungen:**

1. **Nicht im KILLED State**
   - PrÃ¼fen: Status zeigt ACTIVE oder RECOVERING
   - LÃ¶sung: Recovery nur mÃ¶glich von KILLED â†’ RECOVERING

2. **Falscher Approval Code**
   - PrÃ¼fen: `echo $KILL_SWITCH_APPROVAL_CODE`
   - LÃ¶sung: Korrekten Code setzen oder aus `.env` laden

3. **Approval Code fehlt**
   ```bash
   export KILL_SWITCH_APPROVAL_CODE='correct_code_here'
   ```

4. **Cooldown noch aktiv**
   - Symptom: Status zeigt "Cooldown: 120s remaining"
   - LÃ¶sung: Warten bis Cooldown abgelaufen

---

### Problem: Health Check schlÃ¤gt fehl

**Symptom:** Recovery blockiert durch fehlgeschlagene Health Checks

**LÃ¶sung nach Problem:**

**1. Memory-Problem:**
```bash
# Speicher-Verbrauch prÃ¼fen
ps aux --sort=-%mem | head -10

# UnnÃ¶tige Prozesse beenden
kill <PID>

# System neustarten (falls nÃ¶tig)
```

**2. CPU-Problem:**
```bash
# CPU-intensive Prozesse finden
top -o %CPU

# Load Average prÃ¼fen
uptime
```

**3. Exchange-Verbindung:**
```bash
# Netzwerk-Verbindung testen
ping api.kraken.com

# Exchange-Status prÃ¼fen (externe API)
curl https://status.kraken.com/api/v2/status.json
```

**4. Stale Price Data:**
```bash
# Logs prÃ¼fen
tail -f logs/data_pipeline.log

# Data Pipeline neustarten
./scripts/data/restart_pipeline.sh
```

---

### Problem: Gradual Restart zu langsam

**Symptom:** Position Limits bleiben bei 50% stecken

**PrÃ¼fen:**
```bash
# Aktuellen Status anzeigen
python3 -c "
from src.risk_layer.kill_switch.recovery import RecoveryManager
# ... check position_limit_factor
"
```

**LÃ¶sung:**

Option 1: Konfiguration anpassen (fÃ¼r zukÃ¼nftige Recoveries)
```toml
# config/risk/kill_switch.toml
[kill_switch.recovery]
escalation_intervals = [1800, 3600]  # 30min, 1h statt 1h, 2h
```

Option 2: Manuell erhÃ¶hen (nur in NotfÃ¤llen)
- Erfordert Code-Anpassung
- Kontaktiere Engineering Team

---

## ğŸ“ ESKALATION

### Wann eskalieren?

Eskaliere an Engineering Team wenn:
- Kill Switch lÃ¤sst sich nicht deaktivieren
- Unerwartetes Verhalten (State Machine hÃ¤ngt)
- Health Checks schlagen dauerhaft fehl
- Audit Trail zeigt ungewÃ¶hnliche Muster
- System startet nach Recovery nicht korrekt

### Kontakte

**Emergency Hotline:** [Nummer eintragen]

**Engineering On-Call:** [Nummer eintragen]

**Slack:** `#peak-trade-ops`

### Informationen sammeln vor Eskalation

```bash
# 1. Status exportieren
./scripts/ops/kill_switch_ctl.sh status > /tmp/ks_status.txt

# 2. Audit Trail exportieren
./scripts/ops/kill_switch_ctl.sh audit --since 24h > /tmp/ks_audit.txt

# 3. Logs sammeln
tail -n 1000 logs/kill_switch.log > /tmp/ks_logs.txt

# 4. Health Check
./scripts/ops/kill_switch_ctl.sh health > /tmp/ks_health.txt

# Alle Dateien an Team senden
```

---

## ğŸ“‹ CHECKLISTEN

### âœ… TÃ¤gliche PrÃ¼fung

- [ ] Kill Switch Status prÃ¼fen: `kill_switch_ctl.sh status`
- [ ] Letzte Events prÃ¼fen: `kill_switch_ctl.sh audit --since 24h`
- [ ] Health Check durchfÃ¼hren: `kill_switch_ctl.sh health`
- [ ] Approval Code verfÃ¼gbar und aktuell

### âœ… Nach Trigger

- [ ] Ursache identifiziert und dokumentiert
- [ ] Team informiert (Slack + Email)
- [ ] Post-Mortem geplant
- [ ] PrÃ¤ventive MaÃŸnahmen identifiziert

### âœ… Nach Recovery

- [ ] System-StabilitÃ¤t Ã¼berwacht (erste 2 Stunden)
- [ ] Position Limits prÃ¼fen (50% â†’ 75% â†’ 100%)
- [ ] Audit Trail verifiziert
- [ ] Dokumentation aktualisiert

---

**Letzte Aktualisierung:** 2025-12-28  
**Version:** 1.0  
**Maintainer:** Peak_Trade Ops Team
