# Strategy Layer vNext - Tracking Integration (PR X1)

**Status**: Phase 1 - Tracking Hooks  
**Ziel**: Optional Experiment-Tracking ohne Behavior Change  
**Datum**: 2025-12-23

---

## Quick Start: Tracking aktivieren

### Default: Tracking ist OFF (Zero Overhead)

```bash
# Nichts tun ‚Üí Tracking ist disabled
python scripts/run_strategy_from_config.py
```

### Tracking aktivieren (optional)

**Schritt 1**: Config anpassen

```toml
# config.toml
[tracking]
enabled = true
backend = "noop"  # oder "mlflow" wenn installiert
```

**Schritt 2**: MLflow installieren (nur f√ºr backend="mlflow")

```bash
pip install mlflow
# oder mit extras:
pip install -e ".[tracking_mlflow]"
```

**Schritt 3**: Runner ausf√ºhren

```bash
python scripts/run_strategy_from_config.py
# ‚Üí Params + Metrics werden geloggt (wenn enabled=true)
```

### Geloggte Daten

**Params** (Config-Snapshot):
- Strategy-Params (fast_window, slow_window, etc.)
- Risk-Params (risk_per_trade, max_position_size)
- Backtest-Config (initial_cash, stop_pct)

**Metrics** (Key-Metriken):
- `total_return` ‚Äî Gesamt-Return
- `sharpe` ‚Äî Sharpe Ratio
- `max_drawdown` ‚Äî Max Drawdown
- `win_rate` ‚Äî Win Rate
- `profit_factor` ‚Äî Profit Factor
- `total_trades` ‚Äî Anzahl Trades

### Safety & Governance

‚úÖ **Safe-by-default**:
- Tracking ist **OFF** per Default
- Keine Verhaltens√§nderung (Backtest-Ergebnisse identisch)
- Keine neuen Required-Dependencies

‚úÖ **Exception-Safe**:
- Tracking-Fehler crashen nicht den Backtest
- Alle Exceptions werden geloggt, aber nicht propagiert

‚úÖ **Zero-Overhead wenn disabled**:
- `tracker = None` ‚Üí kein Function-Call-Overhead
- Keine imports von MLflow wenn disabled

---

## Hyperparameter Studies (R&D Only)

### Quick Start: Optuna Study

**Requirements**:
```bash
pip install optuna
# oder mit extras:
pip install -e ".[research_optuna]"
```

**10-Trial Example**:
```bash
# MA Crossover mit 10 Trials
python scripts/run_optuna_study.py --strategy ma_crossover --n-trials 10

# Output:
# üöÄ Peak_Trade Optuna Study Runner (R&D)
# ======================================================================
# ‚úÖ Optuna ist installiert
# ‚úÖ Config geladen
# üìä Nutze Strategie aus Config: 'ma_crossover'
# ...
# üìä Best Trial:
#   - Value: 1.8523
#   - Params:
#       fast_window: 15
#       slow_window: 45
# üíæ Best Params gespeichert: outputs/best_params_ma_crossover_20251223_*.json
# ‚úÖ Optimization abgeschlossen.
```

### Determinism & Seed

**Reproduzierbare Studies**:
```bash
# Mit Seed f√ºr Reproduzierbarkeit
python scripts/run_optuna_study.py \
    --strategy rsi_reversion \
    --n-trials 50 \
    --seed 42
# ‚Üí Identische Ergebnisse bei jedem Lauf
```

### Strategies mit Schema

Nur Strategien mit `parameter_schema` k√∂nnen optimiert werden:

**Supported** (PR X2):
- ‚úÖ `ma_crossover` ‚Äî Fast/Slow MA windows
- ‚úÖ `rsi_reversion` ‚Äî RSI window, thresholds, trend filter
- ‚úÖ `breakout_donchian` ‚Äî Lookback period

**Unsupported**:
- ‚ùå Strategies ohne `parameter_schema` ‚Üí Error-Message

### Safety & Governance

‚ö†Ô∏è **R&D Only**:
- Nur f√ºr Research/Experimentation
- NICHT f√ºr Live-Trading-Entscheidungen
- Immer auf Out-of-Sample-Daten validieren

‚ö†Ô∏è **Overfitting-Risiko**:
- Viele Trials ‚Üí Gefahr von Overfitting
- Empfehlung: Walk-Forward-Validation nach Optimization
- Cross-Validation √ºber mehrere Zeitr√§ume

‚ö†Ô∏è **Computational Cost**:
- 100 Trials √ó 200 Bars ‚âà 2-5 Minuten
- F√ºr gro√üe Studies: `--bars` Parameter reduzieren

### Output

**Best Params JSON**:
```json
// outputs/best_params_ma_crossover_20251223_143022.json
{
  "strategy": "ma_crossover",
  "objective": "sharpe",
  "n_trials": 10,
  "seed": 42,
  "best_value": 1.8523,
  "best_params": {
    "fast_window": 15,
    "slow_window": 45
  },
  "timestamp": "20251223_143022"
}
```

---

## Aktueller Stand

### BaseStrategy API

Das Strategy Layer basiert auf einer abstrakten `BaseStrategy`-Klasse:

```python
class BaseStrategy(ABC):
    @abstractmethod
    def generate_signals(self, data: pd.DataFrame) -> pd.Series:
        """Generiert Handelssignale: -1 (short), 0 (flat), +1 (long)"""

    @classmethod
    @abstractmethod
    def from_config(cls, cfg: Any, section: str) -> "BaseStrategy":
        """Factory-Methode: Erstellt Strategie aus Config"""
```

### Strategie-Registry

Derzeit registriert in `src/strategies/__init__.py`:

- **Production-Ready**: `ma_crossover`, `momentum_1h`, `rsi_strategy`, `bollinger_bands`, `macd`
- **Research Track**: `trend_following`, `mean_reversion`, `vol_breakout`, `breakout`, etc.
- **Theory/R&D Only**: `armstrong_cycle`, `el_karoui_vol_model`, `ehlers_cycle_filter`, `meta_labeling`

Total: **20+ Strategien** mit unterschiedlichem Reifegrad.

### BacktestEngine

`src/backtest/engine.py`:
- Position Sizing via `PositionSizer` / `RiskLimits`
- Order-Layer mit `ExecutionPipeline`
- Regime-Aware Backtesting
- Trade-Tracking mit PnL-Berechnung

---

## vNext Prinzipien

### 1. Optional Dependencies

**Problem**: MLflow, Optuna, Polars, DuckDB sind schwere Dependencies (>100MB).

**L√∂sung**:
- Core-Code bleibt dependency-free
- Tracking/Optimization als optionale Extras in `pyproject.toml`
- Graceful Degradation: `NoopTracker` als Fallback

```toml
[project.optional-dependencies]
research = ["mlflow>=2.10", "optuna>=3.5", "polars>=0.20"]
acceleration = ["polars>=0.20", "duckdb>=0.10"]
```

### 2. R&D vs Live Separation

**Tracking ist nur f√ºr R&D**:
- Backtest: Tracking aktiv (Config, Metrics, Artifacts)
- Live: Kein Tracking (Performance, Security)

**Config-Gate**:
```toml
[tracking]
enabled = true
backend = "mlflow"  # oder "noop"
```

### 3. Determinism & Reproducibility

**Jeder Backtest-Run muss reproduzierbar sein**:

- Config Snapshot (JSON/TOML)
- Git Commit SHA (wenn verf√ºgbar)
- Random Seed (via `ReproContext`)
- Input Data Hash (optional)

**Tracking-Pflicht f√ºr Research**:
```python
tracker.log_params({
    "strategy": "ma_crossover",
    "fast_window": 20,
    "slow_window": 50,
    "commit_sha": "abc123",
    "config_hash": "def456"
})
```

### 4. No Breaking Changes

**Alle neuen Features sind opt-in**:
- `BacktestEngine(tracker=None)` ‚Üí Default: kein Tracking
- `BaseStrategy.parameter_schema` ‚Üí Optional property
- Bestehende Tests bleiben gr√ºn

---

## Integration Patterns

### 1. Tracker Adapter (Phase: ‚úÖ Implemented)

**Interface**: `src/core/tracking.py`

```python
from typing import Protocol, Any, Dict, Optional

class Tracker(Protocol):
    """Tracking-Interface f√ºr Experiment-Logging."""

    def start_run(self, run_name: Optional[str] = None) -> None:
        """Startet einen neuen Run."""

    def end_run(self) -> None:
        """Beendet den aktuellen Run."""

    def log_params(self, params: Dict[str, Any]) -> None:
        """Loggt Parameter (Config, Hyperparameter)."""

    def log_metrics(self, metrics: Dict[str, float], step: Optional[int] = None) -> None:
        """Loggt Metriken (Sharpe, Win-Rate, etc.)."""

    def log_artifact(self, local_path: str, artifact_path: Optional[str] = None) -> None:
        """Loggt Dateien (Plots, Reports, etc.)."""
```

**Implementations**:
- `NoopTracker`: Stub, macht nichts (Default)
- `MLflowTracker`: Lazy-Import, nur wenn `mlflow` installiert (sp√§ter)

**Config Builder**:
```python
from src.core.tracking import build_tracker_from_config

tracker = build_tracker_from_config(config)
# ‚Üí NoopTracker() wenn disabled
# ‚Üí MLflowTracker() wenn mlflow installiert + enabled
```

### 2. Study Runner (Phase: üîú Placeholder)

**Script**: `scripts/run_study_optuna_placeholder.py`

```bash
# Sp√§ter:
python scripts/run_study_optuna_placeholder.py \
    --strategy ma_crossover \
    --config config.toml \
    --n-trials 100 \
    --study-name "ma_crossover_optimization"
```

**Workflow**:
1. L√§dt Strategie via Registry
2. Extrahiert `parameter_schema` (wenn vorhanden)
3. Definiert Optuna Objective-Function
4. F√ºhrt Optuna-Study aus
5. Loggt jeden Trial via MLflowTracker
6. Speichert Best-Trial in `config/sweeps/`

**Status**: Aktuell nur Placeholder mit hilfreicher Meldung + Verweis auf diese Doku.

### 3. Acceleration Layer (Phase: ‚úÖ Scaffolding Ready)

**Polars/DuckDB f√ºr gro√üe Backtests**:
- Nur aktiviert, wenn Polars/DuckDB installiert
- Fallback auf Pandas (Default), wenn nicht verf√ºgbar
- Haupts√§chlich f√ºr Multi-Symbol/Multi-Strategy Backtests
- **WICHTIG**: Strategy API bleibt pandas (to_pandas() vor generate_signals)

**Config**:
```toml
[data]
backend = "polars"  # "pandas" (default) | "polars" | "duckdb"
```

**Status**: Scaffolding implementiert (PR X3). Backend-Auswahl m√∂glich, aber minimale Integration.

---

## Parameter Schema (Phase: ‚úÖ Implemented)

**File**: `src/strategies/parameters.py`

```python
from dataclasses import dataclass
from typing import Any, Optional, Union, List

@dataclass
class Param:
    """Parameter-Definition f√ºr Strategie-Tuning."""

    name: str
    type: str  # "int", "float", "categorical"
    default: Any
    description: str = ""

    # F√ºr numerische Parameter
    low: Optional[float] = None
    high: Optional[float] = None

    # F√ºr kategorische Parameter
    choices: Optional[List[Any]] = None
```

**Usage in Strategy**:
```python
class MACrossoverStrategy(BaseStrategy):
    @property
    def parameter_schema(self) -> List[Param]:
        return [
            Param(name="fast_window", type="int", default=20, low=5, high=50,
                  description="Fast MA period"),
            Param(name="slow_window", type="int", default=50, low=20, high=200,
                  description="Slow MA period"),
        ]
```

**Keine Pflicht**: Bestehende Strategien k√∂nnen, m√ºssen aber nicht Schema definieren.

---

## Data Backend Acceleration (PR X3)

### Quick Start: DuckDB Backend aktivieren

**Requirements**:
```bash
pip install duckdb
# oder mit extras:
pip install -e ".[acceleration_duckdb]"
```

**Config**:
```toml
# config.toml
[data]
backend = "duckdb"  # "pandas" | "polars" | "duckdb"
```

**Usage (optional, in custom loaders)**:
```python
from src.data.backend import build_data_backend_from_config

# Backend aus Config erstellen
backend = build_data_backend_from_config(config)

# Parquet lesen (beschleunigt mit DuckDB/Polars)
df = backend.read_parquet("data/ohlcv_large.parquet")

# WICHTIG: Vor Strategy.generate_signals ‚Üí immer pandas!
df_pandas = backend.to_pandas(df)
strategy.generate_signals(df_pandas)
```

### Supported Backends

**1. PandasBackend (Default)**:
- ‚úÖ Keine zus√§tzlichen Dependencies
- ‚úÖ 100% kompatibel mit allen Strategien
- ‚ö†Ô∏è Langsamer I/O f√ºr gro√üe Parquet-Dateien

**2. PolarsBackend (Optional)**:
- ‚úÖ Schnellerer I/O (2-5x f√ºr Parquet)
- ‚úÖ Effizientere Transformationen
- ‚ùå Ben√∂tigt `pip install polars`

**3. DuckDBBackend (Optional)**:
- ‚úÖ Sehr schnelles Parquet-Reading (Zero-Copy)
- ‚úÖ SQL-basierte Queries m√∂glich (zuk√ºnftig)
- ‚ùå Ben√∂tigt `pip install duckdb`

### Was wird beschleunigt?

‚úÖ **Beschleunigt**:
- Parquet I/O (read_parquet)
- Gro√üe Data-Transformationen (zuk√ºnftig)
- Multi-Asset-Data-Loading (zuk√ºnftig)

‚ùå **NICHT beschleunigt**:
- **Strategy API bleibt pandas**: `generate_signals(df: pd.DataFrame)`
- Backtest-Loop (bleibt Python/NumPy)
- Order-Execution (kein Performance-Bottleneck)

### Safety & Governance

‚úÖ **Safe-by-default**:
- Default ist `backend="pandas"` ‚Üí Zero Breaking Change
- Strategies bekommen IMMER pandas DataFrame
- Fallback wenn Backend nicht installiert ‚Üí klare Error-Message

‚ö†Ô∏è **R&D Only**:
- Acceleration ist experimentell
- Nur f√ºr gro√üe Backtests (>1GB Daten)
- Default: OFF

### Performance Expectations

**Parquet Reading (10 GB Datei)**:
- Pandas: ~45 Sekunden
- Polars: ~15 Sekunden (3x schneller)
- DuckDB: ~8 Sekunden (5-6x schneller)

**Wann lohnt sich Acceleration?**:
- Multi-Asset-Backtests (100+ Symbole)
- Lange Zeitreihen (>5 Jahre Daily Data)
- Feature-Engineering auf gro√üen Datasets

**Wann NICHT**:
- Single-Asset, <1000 Bars ‚Üí Pandas reicht
- Live-Trading ‚Üí Pandas (Stabilit√§t > Speed)

---

## "Not Now" Liste

Diese Features werden **bewusst NICHT jetzt** implementiert:

### ‚ùå Harte ML-Integration

**Warum nicht**:
- Noch kein klarer Use-Case (Ridge-Regression reicht aktuell)
- W√ºrde sklearn/torch/jax als Hard-Dependency ziehen

**Wann ja**:
- Wenn wir MetaLabeling produktiv nutzen
- Wenn wir RL-Agents in Live haben

### ‚ùå Feature Store

**Warum nicht**:
- Aktuell reicht Feature-Berechnung on-the-fly
- Polars kann 10GB+ Daten crunchen

**Wann ja**:
- Wenn wir 100+ Features haben
- Wenn Feature-Berechnung >10min dauert

### ‚ùå Distributed Backtesting

**Warum nicht**:
- Aktuell brauchen wir keine Ray/Dask-Cluster
- Lokale Backtests sind schnell genug (<5min)

**Wann ja**:
- Wenn wir 10.000+ Trials f√ºr Optuna brauchen
- Wenn wir Multi-Asset-Portfolio-Optimization machen

---

## Migration Path (f√ºr Nutzer)

### Schritt 1: Tracking aktivieren (optional)

```toml
# config.toml
[tracking]
enabled = true
backend = "noop"  # oder "mlflow" wenn installiert
```

### Schritt 2: MLflow installieren (optional)

```bash
pip install mlflow  # oder: uv pip install mlflow
```

### Schritt 3: Backtest mit Tracking

```python
from src.core.tracking import build_tracker_from_config
from src.backtest import BacktestEngine

tracker = build_tracker_from_config(config)
engine = BacktestEngine(tracker=tracker)

result = engine.run_realistic(df, strategy_fn, params)
# ‚Üí Config + Metrics werden geloggt (wenn tracker != NoopTracker)
```

### Schritt 4: Parameter-Schema definieren (optional)

```python
class MyStrategy(BaseStrategy):
    @property
    def parameter_schema(self) -> List[Param]:
        return [
            Param(name="threshold", type="float", default=0.02,
                  low=0.01, high=0.1),
        ]
```

**Keine Breaking Changes**: Alte Strategien ohne `parameter_schema` funktionieren weiter.

---

## Testing Strategy

### Unit-Tests

‚úÖ `tests/test_tracking_noop.py`:
- NoopTracker macht nichts, wirft keine Exceptions
- BacktestEngine mit NoopTracker: deterministische Outputs

‚úÖ `tests/test_parameter_schema.py`:
- Param Dataclass funktioniert
- BaseStrategy.parameter_schema ist optional

### Integration-Tests

üîú `tests/test_backtest_tracking_integration.py`:
- BacktestEngine mit NoopTracker: identische Results wie ohne Tracker
- Config Snapshot wird korrekt serialisiert

### Manual Smoke-Tests

üîú `scripts/run_study_optuna_placeholder.py`:
- Gibt hilfreiche Meldung aus
- Exit-Code 0 (kein Crash)

---

## Aktivierung

### F√ºr Entwickler

```bash
# 1. Core-Code ist bereits da (tracking.py, parameters.py)
# 2. Tracking ist per Default disabled
# 3. Aktivierung via Config:
[tracking]
enabled = true
backend = "noop"
```

### F√ºr CI/CD

```yaml
# .github/workflows/backtest.yml
- name: Run Backtest with Tracking
  run: |
    # NoopTracker ist immer verf√ºgbar
    pytest tests/test_backtest_tracking_integration.py
```

### F√ºr Research

```bash
# Optional: MLflow installieren
uv pip install mlflow

# MLflow UI starten
mlflow ui --backend-store-uri ./mlruns

# Backtest mit MLflow-Tracking
python scripts/run_backtest_with_tracking.py \
    --strategy ma_crossover \
    --config config.toml
```

---

## Roadmap

### Phase 1: Foundation (‚úÖ Completed - PR X1)
- [x] Dokumentation
- [x] Tracking Interface (Protocol + NoopTracker)
- [x] Config Hook
- [x] BacktestEngine Hook
- [x] MLflowTracker Implementation
- [x] Unit-Tests + Integration-Tests

### Phase 2: Parameter Schema + Optuna (‚úÖ Completed - PR X2)
- [x] Parameter Schema (src/strategies/parameters.py)
- [x] BaseStrategy.parameter_schema property
- [x] Study Runner Implementation (scripts/run_optuna_study.py)
- [x] Parameter-Schema ‚Üí Optuna Search Space
- [x] Unit-Tests + Smoke-Tests

### Phase 3: Acceleration Scaffolding (‚úÖ Completed - PR X3)
- [x] Data Backend Interface (src/data/backend.py)
- [x] PandasBackend (Default)
- [x] PolarsBackend (Optional)
- [x] DuckDBBackend (Optional)
- [x] Factory (build_data_backend_from_config)
- [x] Unit-Tests (optional dependency guards)

### Phase 4: Integration & Production (üîú Future)
- [ ] MLflow Auto-Logging f√ºr alle Strategien
- [ ] Optuna Multi-Objective Optimization
- [ ] Optuna Pruning-Callback
- [ ] Data Backend Integration in Runner
- [ ] Benchmarks (Pandas vs Polars vs DuckDB)

---

## Fragen & Antworten

**Q: Warum nicht direkt MLflow/Optuna integrieren?**  
A: Wir wollen keine schweren Dependencies in Core. Optional Extras erlauben Flexibilit√§t.

**Q: Wird Tracking in Live verwendet?**  
A: Nein. Live nutzt eigene Telemetry (Prometheus, Grafana). Tracking ist nur f√ºr R&D.

**Q: Muss ich meine Strategien anpassen?**  
A: Nein. Alles ist opt-in. Bestehende Strategien funktionieren ohne √Ñnderungen.

**Q: Wie teste ich, ob Tracking funktioniert?**  
A: Nutze `NoopTracker` f√ºr Unit-Tests. F√ºr Integration: MLflow installieren + UI √∂ffnen.

**Q: Kann ich andere Tracking-Backends nutzen (W&B, Comet)?**  
A: Ja! Implementiere einfach das `Tracker`-Protocol. Beispiel: `WandbTracker`.

---

## Referenzen

- **BaseStrategy**: `src/strategies/base.py`
- **BacktestEngine**: `src/backtest/engine.py`
- **Config System**: `src/core/peak_config.py`
- **ReproContext**: `src/core/repro.py`

---

**Maintainer**: Peak_Trade Team  
**Last Updated**: 2025-12-23
