global:
  scrape_interval: 5s
  evaluation_interval: 5s

# Alerting / Recording rules (Ops Pack v1)
# Note: In the default local compose, only this prometheus.yml is mounted.
# To activate rules, mount/copy the rules directory into the container path:
#   /etc/prometheus/rules
rule_files:
  - /etc/prometheus/rules/*.yml
  - /etc/prometheus/rules/*.yaml

scrape_configs:
  # Deterministic demo target so Grafana panels always have data locally.
  # Exporter runs on host (started by scripts/obs/shadow_mvs_local_up.sh).
  - job_name: "shadow_mvs"
    metrics_path: /metrics
    scheme: http
    static_configs:
      - targets: ["host.docker.internal:9109"]

  # Optional: if you run Peak_Trade web locally on the host (default :8000),
  # Prometheus-local will scrape it too (Docker Desktop uses host.docker.internal).
  - job_name: "peak_trade_web"
    metrics_path: /metrics
    scheme: http
    static_configs:
      - targets: ["host.docker.internal:8000"]

  # AI Live Exporter (watch-only, runs on host)
  - job_name: "ai_live"
    metrics_path: /metrics
    scheme: http
    static_configs:
      - targets: ["host.docker.internal:9110"]

  # Strategy/Risk telemetry endpoint on :9111.
  #
  # Default (Mode B): metricsd exposes /metrics continuously via prometheus_client multiprocess mode.
  # Legacy (Mode A): session runners may expose an in-process /metrics server (optional).
  - job_name: "peak_trade_metricsd"
    metrics_path: /metrics
    scheme: http
    static_configs:
      - targets: ["host.docker.internal:9111"]

  # NOTE: Legacy/optional scrape job (Mode A) â€” intentionally disabled by default to
  # avoid duplicate series (job label differences) when metricsd is enabled.
  #
  # - job_name: "peak_trade_session"
  #   metrics_path: /metrics
  #   scheme: http
  #   static_configs:
  #     - targets: ["host.docker.internal:9111"]
