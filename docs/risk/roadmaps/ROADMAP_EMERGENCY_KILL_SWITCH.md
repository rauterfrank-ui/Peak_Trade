# Peak_Trade â€“ Emergency Kill Switch Roadmap

**Version:** 1.0  
**Datum:** 2025-12-27  
**Status:** ğŸ“‹ GEPLANT  
**Layer:** Risk Layer â€“ Defense in Depth Layer 4  
**PrioritÃ¤t:** ğŸ”´ KRITISCH (Blocker fÃ¼r Live-Trading)

---

## ğŸ¯ Executive Summary

Der **Emergency Kill Switch** ist die letzte Verteidigungslinie im 4-Layer Defense-in-Depth System von Peak_Trade. Er ermÃ¶glicht das sofortige Stoppen aller Trading-AktivitÃ¤ten bei kritischen Ereignissen â€“ unabhÃ¤ngig von allen anderen Systemkomponenten.

**Kernprinzip:** Der Kill Switch muss *immer* funktionieren, auch wenn alle anderen Systeme ausfallen.

---

## ğŸ“Š Phasen-Ãœbersicht

| Phase | Name | Dauer | Status | AbhÃ¤ngigkeiten |
|-------|------|-------|--------|----------------|
| **1** | Foundation & State Machine | 3-4 Tage | â¬œ Geplant | Keine |
| **2** | Trigger-Mechanismen | 4-5 Tage | â¬œ Geplant | Phase 1 |
| **3** | Recovery & Reactivation | 3-4 Tage | â¬œ Geplant | Phase 2 |
| **4** | Persistence & Audit | 2-3 Tage | â¬œ Geplant | Phase 3 |
| **5** | Integration & API | 3-4 Tage | â¬œ Geplant | Phase 4 |
| **6** | Testing & Chaos Engineering | 4-5 Tage | â¬œ Geplant | Phase 5 |
| **7** | Dokumentation & Runbooks | 2-3 Tage | â¬œ Geplant | Phase 6 |

**GeschÃ¤tzte Gesamtdauer:** 21-28 Tage (4-5 Wochen)

---

## ğŸ”´ Phase 1: Foundation & State Machine

**Ziel:** Kernarchitektur des Kill Switch mit robuster State Machine implementieren.

**Dauer:** 3-4 Tage

### 1.1 State Machine Design

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    KILL SWITCH STATE MACHINE                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       trigger()       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚    â”‚  ACTIVE  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶  â”‚   KILLED     â”‚         â”‚
â”‚    â”‚ (normal) â”‚                       â”‚ (emergency)  â”‚         â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚         â–²                                    â”‚                  â”‚
â”‚         â”‚         recover()                  â”‚                  â”‚
â”‚         â”‚    (requires approval)             â”‚                  â”‚
â”‚         â”‚                                    â–¼                  â”‚
â”‚         â”‚                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚  RECOVERING  â”‚          â”‚
â”‚                                      â”‚  (cooldown)  â”‚          â”‚
â”‚                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                                 â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                â”‚
â”‚    â”‚ DISABLED â”‚  â—€â”€â”€ Nur via Config (Backtest-Mode)           â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 Deliverables

| Datei | Beschreibung |
|-------|--------------|
| `src/risk_layer/kill_switch/state.py` | State Machine Enum + Transitions |
| `src/risk_layer/kill_switch/core.py` | KillSwitch Hauptklasse |
| `src/risk_layer/kill_switch/__init__.py` | Public API Exports |
| `tests/risk_layer/kill_switch/test_state_machine.py` | State Transition Tests |
| `config/risk/kill_switch.toml` | Konfiguration |

### 1.3 Implementierung

```python
# src/risk_layer/kill_switch/state.py
"""Kill Switch State Machine fÃ¼r Peak_Trade."""

from enum import Enum, auto
from dataclasses import dataclass
from datetime import datetime
from typing import Optional


class KillSwitchState(Enum):
    """ZustÃ¤nde des Kill Switch."""
    ACTIVE = auto()      # Normal-Betrieb, Trading erlaubt
    KILLED = auto()      # Notfall-Stopp, kein Trading
    RECOVERING = auto()  # Cooldown nach Recovery-Anfrage
    DISABLED = auto()    # Deaktiviert (nur Backtest)


@dataclass(frozen=True)
class KillSwitchEvent:
    """Immutable Event fÃ¼r Audit-Trail."""
    timestamp: datetime
    previous_state: KillSwitchState
    new_state: KillSwitchState
    trigger_reason: str
    triggered_by: str  # "system", "manual", "threshold"
    metadata: dict


class StateTransitionError(Exception):
    """UngÃ¼ltiger State-Ãœbergang."""
    pass
```

```python
# src/risk_layer/kill_switch/core.py
"""Kill Switch Core Implementation."""

from datetime import datetime, timedelta
from typing import Optional, Callable, List
from threading import RLock
import logging

from .state import KillSwitchState, KillSwitchEvent, StateTransitionError


class KillSwitch:
    """
    Emergency Kill Switch fÃ¼r Peak_Trade.

    Layer 4 der Defense-in-Depth Architektur.
    Letzte Verteidigungslinie - muss IMMER funktionieren.

    Thread-safe durch RLock.
    """

    # Erlaubte State-ÃœbergÃ¤nge
    VALID_TRANSITIONS = {
        KillSwitchState.ACTIVE: {KillSwitchState.KILLED},
        KillSwitchState.KILLED: {KillSwitchState.RECOVERING},
        KillSwitchState.RECOVERING: {KillSwitchState.ACTIVE, KillSwitchState.KILLED},
        KillSwitchState.DISABLED: set(),  # Keine Transitions
    }

    def __init__(
        self,
        config: dict,
        logger: Optional[logging.Logger] = None,
    ):
        """
        Initialisiert den Kill Switch.

        Args:
            config: Konfiguration aus kill_switch.toml
            logger: Optional Logger Instance
        """
        self._lock = RLock()
        self._state = KillSwitchState.ACTIVE
        self._config = config
        self._logger = logger or logging.getLogger(__name__)

        # Event History fÃ¼r Audit
        self._events: List[KillSwitchEvent] = []

        # Callbacks fÃ¼r State Changes
        self._on_kill_callbacks: List[Callable] = []
        self._on_recover_callbacks: List[Callable] = []

        # Timestamps
        self._killed_at: Optional[datetime] = None
        self._recovery_started_at: Optional[datetime] = None

        # Cooldown-Konfiguration
        self._recovery_cooldown = timedelta(
            seconds=config.get("recovery_cooldown_seconds", 300)
        )

        self._logger.info(
            f"KillSwitch initialisiert: state={self._state.name}, "
            f"cooldown={self._recovery_cooldown}"
        )

    @property
    def state(self) -> KillSwitchState:
        """Aktueller State (thread-safe read)."""
        with self._lock:
            return self._state

    @property
    def is_killed(self) -> bool:
        """True wenn Trading gestoppt."""
        return self.state in (KillSwitchState.KILLED, KillSwitchState.RECOVERING)

    @property
    def is_active(self) -> bool:
        """True wenn Trading erlaubt."""
        return self.state == KillSwitchState.ACTIVE

    def trigger(
        self,
        reason: str,
        triggered_by: str = "system",
        metadata: Optional[dict] = None,
    ) -> bool:
        """
        Aktiviert den Kill Switch (EMERGENCY STOP).

        Args:
            reason: Grund fÃ¼r den Trigger (fÃ¼r Audit)
            triggered_by: Wer hat getriggert ("system", "manual", "threshold")
            metadata: ZusÃ¤tzliche Daten fÃ¼r Audit

        Returns:
            True wenn erfolgreich getriggert
        """
        with self._lock:
            if self._state == KillSwitchState.DISABLED:
                self._logger.warning("Kill Switch ist DISABLED (Backtest-Mode)")
                return False

            if self._state == KillSwitchState.KILLED:
                self._logger.warning("Kill Switch bereits KILLED")
                return True  # Bereits im gewÃ¼nschten Zustand

            # State Transition
            previous = self._state
            self._state = KillSwitchState.KILLED
            self._killed_at = datetime.utcnow()

            # Event loggen
            event = KillSwitchEvent(
                timestamp=self._killed_at,
                previous_state=previous,
                new_state=self._state,
                trigger_reason=reason,
                triggered_by=triggered_by,
                metadata=metadata or {},
            )
            self._events.append(event)

            self._logger.critical(
                f"ğŸš¨ KILL SWITCH TRIGGERED: {reason} "
                f"(by={triggered_by}, from={previous.name})"
            )

            # Callbacks ausfÃ¼hren
            self._execute_callbacks(self._on_kill_callbacks, event)

            return True

    def request_recovery(
        self,
        approved_by: str,
        approval_code: Optional[str] = None,
    ) -> bool:
        """
        Startet Recovery-Prozess (mit Cooldown).

        Args:
            approved_by: Wer genehmigt die Recovery
            approval_code: Optional BestÃ¤tigungscode

        Returns:
            True wenn Recovery gestartet
        """
        with self._lock:
            if self._state != KillSwitchState.KILLED:
                self._logger.warning(
                    f"Recovery nur von KILLED mÃ¶glich, aktuell: {self._state.name}"
                )
                return False

            # Approval validieren
            if self._config.get("require_approval_code", False):
                if not self._validate_approval_code(approval_code):
                    self._logger.error("UngÃ¼ltiger Approval Code")
                    return False

            # State Transition
            previous = self._state
            self._state = KillSwitchState.RECOVERING
            self._recovery_started_at = datetime.utcnow()

            event = KillSwitchEvent(
                timestamp=self._recovery_started_at,
                previous_state=previous,
                new_state=self._state,
                trigger_reason=f"Recovery requested by {approved_by}",
                triggered_by="manual",
                metadata={"approved_by": approved_by},
            )
            self._events.append(event)

            self._logger.warning(
                f"â³ RECOVERY STARTED: cooldown={self._recovery_cooldown}, "
                f"approved_by={approved_by}"
            )

            return True

    def complete_recovery(self) -> bool:
        """
        SchlieÃŸt Recovery ab (nach Cooldown).

        Returns:
            True wenn erfolgreich reaktiviert
        """
        with self._lock:
            if self._state != KillSwitchState.RECOVERING:
                return False

            # Cooldown prÃ¼fen
            if self._recovery_started_at:
                elapsed = datetime.utcnow() - self._recovery_started_at
                if elapsed < self._recovery_cooldown:
                    remaining = self._recovery_cooldown - elapsed
                    self._logger.warning(
                        f"Cooldown noch aktiv: {remaining.seconds}s verbleibend"
                    )
                    return False

            # State Transition
            previous = self._state
            self._state = KillSwitchState.ACTIVE

            event = KillSwitchEvent(
                timestamp=datetime.utcnow(),
                previous_state=previous,
                new_state=self._state,
                trigger_reason="Recovery completed",
                triggered_by="system",
                metadata={},
            )
            self._events.append(event)

            # Reset Timestamps
            self._killed_at = None
            self._recovery_started_at = None

            self._logger.info("âœ… KILL SWITCH RECOVERED: Trading wieder aktiv")

            # Callbacks ausfÃ¼hren
            self._execute_callbacks(self._on_recover_callbacks, event)

            return True

    def check_and_block(self) -> bool:
        """
        PrÃ¼ft ob Trading erlaubt ist.

        Returns:
            True wenn Trading BLOCKIERT ist

        Verwendung:
            if kill_switch.check_and_block():
                raise TradingBlockedError("Kill Switch aktiv")
        """
        return self.is_killed

    def register_on_kill(self, callback: Callable[[KillSwitchEvent], None]):
        """Registriert Callback fÃ¼r Kill-Events."""
        self._on_kill_callbacks.append(callback)

    def register_on_recover(self, callback: Callable[[KillSwitchEvent], None]):
        """Registriert Callback fÃ¼r Recovery-Events."""
        self._on_recover_callbacks.append(callback)

    def get_audit_trail(self) -> List[KillSwitchEvent]:
        """Gibt alle Events fÃ¼r Audit zurÃ¼ck."""
        with self._lock:
            return list(self._events)

    def _validate_approval_code(self, code: Optional[str]) -> bool:
        """Validiert Approval Code (Implementierung TBD)."""
        expected = self._config.get("approval_code")
        return code == expected if expected else True

    def _execute_callbacks(
        self,
        callbacks: List[Callable],
        event: KillSwitchEvent,
    ):
        """FÃ¼hrt Callbacks sicher aus."""
        for callback in callbacks:
            try:
                callback(event)
            except Exception as e:
                self._logger.error(f"Callback-Fehler: {e}")
```

### 1.4 Konfiguration

```toml
# config/risk/kill_switch.toml

[kill_switch]
# Allgemeine Einstellungen
enabled = true
mode = "active"  # "active" | "disabled" (nur Backtest)

# Recovery-Einstellungen
recovery_cooldown_seconds = 300  # 5 Minuten Cooldown
require_approval_code = true
# approval_code = "EMERGENCY_RECOVERY_2025"  # In .env auslagern!

# Logging
log_level = "INFO"
audit_retention_days = 90

# Persistence
persist_state = true
state_file = "data/kill_switch_state.json"
```

### 1.5 Acceptance Criteria

- [ ] State Machine mit 4 States implementiert
- [ ] Thread-safe durch RLock
- [ ] Alle State-ÃœbergÃ¤nge validiert
- [ ] Event-History fÃ¼r Audit
- [ ] Callback-System fÃ¼r Kill/Recover
- [ ] Cooldown-Mechanismus funktioniert
- [ ] Unit Tests: 100% State Coverage
- [ ] Config-driven (TOML)

### 1.6 Tests

```python
# tests/risk_layer/kill_switch/test_state_machine.py

import pytest
from src.risk.kill_switch import KillSwitch, KillSwitchState


@pytest.fixture
def kill_switch():
    """Erstellt KillSwitch mit Test-Config."""
    config = {
        "enabled": True,
        "recovery_cooldown_seconds": 1,  # Kurz fÃ¼r Tests
        "require_approval_code": False,
    }
    return KillSwitch(config)


class TestStateTransitions:
    """Tests fÃ¼r State Machine."""

    def test_initial_state_is_active(self, kill_switch):
        """Initial State sollte ACTIVE sein."""
        assert kill_switch.state == KillSwitchState.ACTIVE
        assert kill_switch.is_active
        assert not kill_switch.is_killed

    def test_trigger_changes_to_killed(self, kill_switch):
        """Trigger sollte zu KILLED wechseln."""
        result = kill_switch.trigger("Test Trigger")

        assert result is True
        assert kill_switch.state == KillSwitchState.KILLED
        assert kill_switch.is_killed
        assert not kill_switch.is_active

    def test_double_trigger_is_idempotent(self, kill_switch):
        """Doppelter Trigger sollte safe sein."""
        kill_switch.trigger("First")
        result = kill_switch.trigger("Second")

        assert result is True
        assert kill_switch.state == KillSwitchState.KILLED

    def test_recovery_starts_cooldown(self, kill_switch):
        """Recovery sollte Cooldown starten."""
        kill_switch.trigger("Test")
        result = kill_switch.request_recovery("operator")

        assert result is True
        assert kill_switch.state == KillSwitchState.RECOVERING

    def test_recovery_requires_killed_state(self, kill_switch):
        """Recovery nur von KILLED mÃ¶glich."""
        result = kill_switch.request_recovery("operator")

        assert result is False
        assert kill_switch.state == KillSwitchState.ACTIVE

    def test_complete_recovery_after_cooldown(self, kill_switch):
        """Complete Recovery nach Cooldown."""
        import time

        kill_switch.trigger("Test")
        kill_switch.request_recovery("operator")

        # Cooldown abwarten (1 Sekunde in Test-Config)
        time.sleep(1.1)

        result = kill_switch.complete_recovery()

        assert result is True
        assert kill_switch.state == KillSwitchState.ACTIVE

    def test_complete_recovery_blocked_during_cooldown(self, kill_switch):
        """Complete Recovery blockiert wÃ¤hrend Cooldown."""
        kill_switch.trigger("Test")
        kill_switch.request_recovery("operator")

        # Sofort versuchen (vor Cooldown)
        result = kill_switch.complete_recovery()

        assert result is False
        assert kill_switch.state == KillSwitchState.RECOVERING


class TestAuditTrail:
    """Tests fÃ¼r Audit-FunktionalitÃ¤t."""

    def test_events_are_recorded(self, kill_switch):
        """Events sollten aufgezeichnet werden."""
        kill_switch.trigger("Test Reason", triggered_by="manual")

        events = kill_switch.get_audit_trail()

        assert len(events) == 1
        assert events[0].trigger_reason == "Test Reason"
        assert events[0].triggered_by == "manual"
        assert events[0].previous_state == KillSwitchState.ACTIVE
        assert events[0].new_state == KillSwitchState.KILLED


class TestCheckAndBlock:
    """Tests fÃ¼r Trading-Gate."""

    def test_check_and_block_returns_false_when_active(self, kill_switch):
        """check_and_block() False wenn aktiv."""
        assert kill_switch.check_and_block() is False

    def test_check_and_block_returns_true_when_killed(self, kill_switch):
        """check_and_block() True wenn killed."""
        kill_switch.trigger("Test")
        assert kill_switch.check_and_block() is True

    def test_check_and_block_returns_true_when_recovering(self, kill_switch):
        """check_and_block() True wÃ¤hrend Recovery."""
        kill_switch.trigger("Test")
        kill_switch.request_recovery("operator")
        assert kill_switch.check_and_block() is True
```

---

## ğŸŸ  Phase 2: Trigger-Mechanismen

**Ziel:** Automatische und manuelle Trigger fÃ¼r verschiedene Szenarien.

**Dauer:** 4-5 Tage

### 2.1 Trigger-Typen

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      TRIGGER-MECHANISMEN                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚ MANUELLE TRIGGERâ”‚    â”‚ AUTO TRIGGER    â”‚                    â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                    â”‚
â”‚  â”‚ â€¢ CLI Command   â”‚    â”‚ â€¢ Drawdown Limitâ”‚                    â”‚
â”‚  â”‚ â€¢ API Endpoint  â”‚    â”‚ â€¢ Daily Loss    â”‚                    â”‚
â”‚  â”‚ â€¢ Hotkey        â”‚    â”‚ â€¢ Volatility    â”‚                    â”‚
â”‚  â”‚ â€¢ Panic Button  â”‚    â”‚ â€¢ System Health â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚           â”‚                      â”‚                              â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚                      â–¼                                          â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚
â”‚              â”‚  KILL SWITCH  â”‚                                  â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚ EXTERNAL TRIGGERâ”‚    â”‚ WATCHDOG        â”‚                    â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                    â”‚
â”‚  â”‚ â€¢ Exchange Down â”‚    â”‚ â€¢ Heartbeat     â”‚                    â”‚
â”‚  â”‚ â€¢ Network Error â”‚    â”‚ â€¢ Process Check â”‚                    â”‚
â”‚  â”‚ â€¢ API Limit     â”‚    â”‚ â€¢ Memory/CPU    â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Deliverables

| Datei | Beschreibung |
|-------|--------------|
| `src/risk_layer/kill_switch/triggers/__init__.py` | Trigger Module |
| `src/risk_layer/kill_switch/triggers/base.py` | Abstract Base Trigger |
| `src/risk_layer/kill_switch/triggers/threshold.py` | Threshold-basierte Trigger |
| `src/risk_layer/kill_switch/triggers/manual.py` | Manuelle Trigger |
| `src/risk_layer/kill_switch/triggers/watchdog.py` | System Watchdog |
| `src/risk_layer/kill_switch/triggers/external.py` | Externe Trigger (Exchange, Network) |
| `tests/risk_layer/kill_switch/test_triggers.py` | Trigger Tests |

### 2.3 Threshold-Trigger Konfiguration

```toml
# config/risk/kill_switch.toml

[kill_switch.triggers.drawdown]
enabled = true
type = "threshold"
metric = "portfolio_drawdown"
threshold = -0.15  # -15% Drawdown
operator = "lt"    # less than
cooldown_seconds = 0  # Sofort triggern

[kill_switch.triggers.daily_loss]
enabled = true
type = "threshold"
metric = "daily_pnl"
threshold = -0.05  # -5% Tagesverlust
operator = "lt"
cooldown_seconds = 0

[kill_switch.triggers.volatility_spike]
enabled = true
type = "threshold"
metric = "realized_volatility_1h"
threshold = 0.10  # 10% stÃ¼ndliche VolatilitÃ¤t
operator = "gt"   # greater than
cooldown_seconds = 3600  # 1h Cooldown nach Trigger

[kill_switch.triggers.exchange_disconnect]
enabled = true
type = "external"
check_interval_seconds = 30
max_consecutive_failures = 3

[kill_switch.triggers.system_health]
enabled = true
type = "watchdog"
heartbeat_interval_seconds = 60
max_missed_heartbeats = 3
memory_threshold_percent = 90
cpu_threshold_percent = 95
```

### 2.4 Implementierung

```python
# src/risk_layer/kill_switch/triggers/base.py
"""Base Trigger Interface."""

from abc import ABC, abstractmethod
from dataclasses import dataclass
from datetime import datetime
from typing import Optional


@dataclass
class TriggerResult:
    """Ergebnis einer Trigger-PrÃ¼fung."""
    should_trigger: bool
    reason: str
    metric_value: Optional[float] = None
    threshold: Optional[float] = None
    metadata: dict = None

    def __post_init__(self):
        self.metadata = self.metadata or {}


class BaseTrigger(ABC):
    """Abstract Base Class fÃ¼r Trigger."""

    def __init__(self, name: str, config: dict):
        self.name = name
        self.config = config
        self.enabled = config.get("enabled", True)
        self._last_triggered: Optional[datetime] = None
        self._cooldown_seconds = config.get("cooldown_seconds", 0)

    @abstractmethod
    def check(self, context: dict) -> TriggerResult:
        """
        PrÃ¼ft ob Trigger ausgelÃ¶st werden soll.

        Args:
            context: Aktueller System-Kontext (Metriken, State)

        Returns:
            TriggerResult mit Entscheidung
        """
        pass

    def is_on_cooldown(self) -> bool:
        """PrÃ¼ft ob Trigger noch im Cooldown ist."""
        if not self._last_triggered or self._cooldown_seconds == 0:
            return False

        elapsed = (datetime.utcnow() - self._last_triggered).total_seconds()
        return elapsed < self._cooldown_seconds

    def mark_triggered(self):
        """Markiert Trigger als ausgelÃ¶st."""
        self._last_triggered = datetime.utcnow()
```

```python
# src/risk_layer/kill_switch/triggers/threshold.py
"""Threshold-basierte Trigger."""

from typing import Callable, Dict, Any
import operator as op

from .base import BaseTrigger, TriggerResult


class ThresholdTrigger(BaseTrigger):
    """
    Trigger basierend auf Metrik-Schwellwerten.

    Beispiel:
        - Drawdown > -15% â†’ Kill
        - Daily Loss > -5% â†’ Kill
        - Volatility > 10% â†’ Kill
    """

    OPERATORS: Dict[str, Callable] = {
        "lt": op.lt,      # less than
        "le": op.le,      # less or equal
        "gt": op.gt,      # greater than
        "ge": op.ge,      # greater or equal
        "eq": op.eq,      # equal
        "ne": op.ne,      # not equal
    }

    def __init__(self, name: str, config: dict):
        super().__init__(name, config)
        self.metric_name = config["metric"]
        self.threshold = config["threshold"]
        self.operator_name = config.get("operator", "lt")
        self.operator = self.OPERATORS[self.operator_name]

    def check(self, context: dict) -> TriggerResult:
        """PrÃ¼ft Metrik gegen Threshold."""
        if not self.enabled:
            return TriggerResult(
                should_trigger=False,
                reason=f"Trigger '{self.name}' disabled"
            )

        if self.is_on_cooldown():
            return TriggerResult(
                should_trigger=False,
                reason=f"Trigger '{self.name}' on cooldown"
            )

        # Metrik aus Context holen
        metric_value = context.get(self.metric_name)

        if metric_value is None:
            return TriggerResult(
                should_trigger=False,
                reason=f"Metric '{self.metric_name}' not found in context"
            )

        # Threshold prÃ¼fen
        should_trigger = self.operator(metric_value, self.threshold)

        if should_trigger:
            self.mark_triggered()
            return TriggerResult(
                should_trigger=True,
                reason=(
                    f"{self.metric_name}={metric_value:.4f} "
                    f"{self.operator_name} {self.threshold}"
                ),
                metric_value=metric_value,
                threshold=self.threshold,
                metadata={
                    "trigger_name": self.name,
                    "trigger_type": "threshold",
                    "operator": self.operator_name,
                }
            )

        return TriggerResult(
            should_trigger=False,
            reason=f"Threshold not reached: {metric_value:.4f}",
            metric_value=metric_value,
            threshold=self.threshold,
        )
```

```python
# src/risk_layer/kill_switch/triggers/watchdog.py
"""System Watchdog Trigger."""

import psutil
from datetime import datetime, timedelta
from typing import Optional

from .base import BaseTrigger, TriggerResult


class WatchdogTrigger(BaseTrigger):
    """
    System Health Watchdog.

    Ãœberwacht:
    - Heartbeat (Prozess lebt)
    - Memory Usage
    - CPU Usage
    """

    def __init__(self, name: str, config: dict):
        super().__init__(name, config)
        self.heartbeat_interval = timedelta(
            seconds=config.get("heartbeat_interval_seconds", 60)
        )
        self.max_missed = config.get("max_missed_heartbeats", 3)
        self.memory_threshold = config.get("memory_threshold_percent", 90)
        self.cpu_threshold = config.get("cpu_threshold_percent", 95)

        self._last_heartbeat: Optional[datetime] = None
        self._missed_heartbeats = 0

    def heartbeat(self):
        """Registriert einen Heartbeat."""
        self._last_heartbeat = datetime.utcnow()
        self._missed_heartbeats = 0

    def check(self, context: dict) -> TriggerResult:
        """PrÃ¼ft System Health."""
        if not self.enabled:
            return TriggerResult(
                should_trigger=False,
                reason=f"Watchdog '{self.name}' disabled"
            )

        issues = []

        # Heartbeat prÃ¼fen
        if self._last_heartbeat:
            elapsed = datetime.utcnow() - self._last_heartbeat
            if elapsed > self.heartbeat_interval:
                self._missed_heartbeats += 1
                if self._missed_heartbeats >= self.max_missed:
                    issues.append(
                        f"Missed {self._missed_heartbeats} heartbeats"
                    )

        # Memory prÃ¼fen
        memory = psutil.virtual_memory()
        if memory.percent > self.memory_threshold:
            issues.append(
                f"Memory critical: {memory.percent:.1f}% > {self.memory_threshold}%"
            )

        # CPU prÃ¼fen
        cpu = psutil.cpu_percent(interval=0.1)
        if cpu > self.cpu_threshold:
            issues.append(
                f"CPU critical: {cpu:.1f}% > {self.cpu_threshold}%"
            )

        if issues:
            return TriggerResult(
                should_trigger=True,
                reason="; ".join(issues),
                metadata={
                    "trigger_name": self.name,
                    "trigger_type": "watchdog",
                    "memory_percent": memory.percent,
                    "cpu_percent": cpu,
                    "missed_heartbeats": self._missed_heartbeats,
                }
            )

        return TriggerResult(
            should_trigger=False,
            reason="System health OK",
            metadata={
                "memory_percent": memory.percent,
                "cpu_percent": cpu,
            }
        )
```

### 2.5 Acceptance Criteria

- [ ] ThresholdTrigger fÃ¼r Drawdown, Daily Loss, Volatility
- [ ] WatchdogTrigger fÃ¼r Heartbeat, Memory, CPU
- [ ] ExternalTrigger fÃ¼r Exchange-Verbindung
- [ ] ManualTrigger fÃ¼r CLI/API
- [ ] Cooldown-Mechanismus pro Trigger
- [ ] Trigger-Registry fÃ¼r dynamische Konfiguration
- [ ] Unit Tests fÃ¼r jeden Trigger-Typ
- [ ] Integration Test: Trigger â†’ Kill Switch

---

## ğŸŸ¡ Phase 3: Recovery & Reactivation

**Ziel:** Sichere, kontrollierte Wiederaufnahme des Tradings.

**Dauer:** 3-4 Tage

### 3.1 Recovery-Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      RECOVERY WORKFLOW                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                              â”‚
â”‚    â”‚   KILLED   â”‚                                              â”‚
â”‚    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                              â”‚
â”‚          â”‚                                                      â”‚
â”‚          â–¼                                                      â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚    â”‚ 1. RECOVERY REQUEST                     â”‚                  â”‚
â”‚    â”‚    â€¢ Operator initiiert                â”‚                  â”‚
â”‚    â”‚    â€¢ Approval Code eingeben            â”‚                  â”‚
â”‚    â”‚    â€¢ Reason dokumentieren              â”‚                  â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                      â”‚                                          â”‚
â”‚                      â–¼                                          â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚    â”‚ 2. VALIDATION                          â”‚                  â”‚
â”‚    â”‚    â€¢ Approval Code prÃ¼fen              â”‚                  â”‚
â”‚    â”‚    â€¢ System Health Check               â”‚                  â”‚
â”‚    â”‚    â€¢ Trigger-Conditions prÃ¼fen         â”‚                  â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                      â”‚                                          â”‚
â”‚                      â–¼                                          â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚    â”‚ 3. COOLDOWN                            â”‚                  â”‚
â”‚    â”‚    â€¢ Wartezeit (default: 5 min)        â”‚                  â”‚
â”‚    â”‚    â€¢ Keine neuen Orders                â”‚                  â”‚
â”‚    â”‚    â€¢ Monitoring aktiv                  â”‚                  â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                      â”‚                                          â”‚
â”‚                      â–¼                                          â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚    â”‚ 4. GRADUAL RESTART                     â”‚                  â”‚
â”‚    â”‚    â€¢ Position Limits reduziert (50%)   â”‚                  â”‚
â”‚    â”‚    â€¢ Nach 1h: Normal Limits            â”‚                  â”‚
â”‚    â”‚    â€¢ Enhanced Monitoring               â”‚                  â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                      â”‚                                          â”‚
â”‚                      â–¼                                          â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚    â”‚ 5. ACTIVE                              â”‚                  â”‚
â”‚    â”‚    â€¢ Trading wieder erlaubt            â”‚                  â”‚
â”‚    â”‚    â€¢ Audit Event logged                â”‚                  â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 Deliverables

| Datei | Beschreibung |
|-------|--------------|
| `src/risk_layer/kill_switch/recovery.py` | Recovery Manager |
| `src/risk_layer/kill_switch/health_check.py` | Pre-Recovery Health Checks |
| `tests/risk_layer/kill_switch/test_recovery.py` | Recovery Tests |

**Geplant (TODO):**
- gradual_restart.py - Gradual Restart Logic

### 3.3 Recovery-Konfiguration

```toml
# config/risk/kill_switch.toml

[kill_switch.recovery]
# Basis-Einstellungen
cooldown_seconds = 300           # 5 Minuten Cooldown
require_approval_code = true
require_health_check = true
require_trigger_clear = true     # Trigger muss "clear" sein

# Gradual Restart
gradual_restart_enabled = true
initial_position_limit_factor = 0.5  # 50% der normalen Limits
escalation_intervals = [3600, 7200]  # Nach 1h: 75%, nach 2h: 100%
escalation_factors = [0.75, 1.0]

# Health Check Requirements
min_memory_available_mb = 512
max_cpu_percent = 80
require_exchange_connection = true
require_price_feed = true

# Zweistufige Approval (fÃ¼r Production)
require_dual_approval = false   # SpÃ¤ter fÃ¼r Live
second_approver_required = false
```

### 3.4 Implementierung

```python
# src/risk_layer/kill_switch/recovery.py
"""Recovery Manager fÃ¼r Kill Switch."""

from dataclasses import dataclass
from datetime import datetime, timedelta
from typing import Optional, List
from enum import Enum, auto
import logging

from .state import KillSwitchState
from .health_check import HealthChecker, HealthCheckResult


class RecoveryStage(Enum):
    """Recovery-Phasen."""
    PENDING = auto()        # Warte auf Approval
    VALIDATING = auto()     # Health Checks
    COOLDOWN = auto()       # Cooldown-Phase
    GRADUAL_RESTART = auto() # Limitierter Neustart
    COMPLETE = auto()       # VollstÃ¤ndig recovered


@dataclass
class RecoveryRequest:
    """Recovery-Anfrage."""
    requested_at: datetime
    requested_by: str
    approval_code: str
    reason: str
    stage: RecoveryStage = RecoveryStage.PENDING
    approved_at: Optional[datetime] = None
    health_check_result: Optional[HealthCheckResult] = None


class RecoveryManager:
    """
    Verwaltet den Recovery-Prozess nach Kill Switch Trigger.

    Stellt sicher, dass Recovery:
    - Autorisiert ist (Approval Code)
    - System-Gesundheit geprÃ¼ft wurde
    - Kontrolliert erfolgt (Cooldown + Gradual Restart)
    """

    def __init__(
        self,
        config: dict,
        health_checker: HealthChecker,
        logger: Optional[logging.Logger] = None,
    ):
        self.config = config
        self.health_checker = health_checker
        self._logger = logger or logging.getLogger(__name__)

        self._current_request: Optional[RecoveryRequest] = None
        self._position_limit_factor = 1.0  # Normal

        # Gradual Restart Config
        self._gradual_enabled = config.get("gradual_restart_enabled", True)
        self._initial_factor = config.get("initial_position_limit_factor", 0.5)
        self._intervals = config.get("escalation_intervals", [3600, 7200])
        self._factors = config.get("escalation_factors", [0.75, 1.0])

    def request_recovery(
        self,
        requested_by: str,
        approval_code: str,
        reason: str,
    ) -> RecoveryRequest:
        """
        Startet Recovery-Anfrage.

        Args:
            requested_by: Operator-Name
            approval_code: BestÃ¤tigungscode
            reason: Grund fÃ¼r Recovery

        Returns:
            RecoveryRequest Objekt
        """
        self._current_request = RecoveryRequest(
            requested_at=datetime.utcnow(),
            requested_by=requested_by,
            approval_code=approval_code,
            reason=reason,
        )

        self._logger.info(
            f"Recovery requested by {requested_by}: {reason}"
        )

        return self._current_request

    def validate_approval(self, expected_code: str) -> bool:
        """Validiert Approval Code."""
        if not self._current_request:
            return False

        if self._current_request.approval_code != expected_code:
            self._logger.warning("Invalid approval code")
            return False

        self._current_request.approved_at = datetime.utcnow()
        self._current_request.stage = RecoveryStage.VALIDATING

        return True

    def run_health_checks(self) -> HealthCheckResult:
        """FÃ¼hrt Health Checks durch."""
        if not self._current_request:
            raise ValueError("No active recovery request")

        result = self.health_checker.check_all()
        self._current_request.health_check_result = result

        if result.is_healthy:
            self._current_request.stage = RecoveryStage.COOLDOWN
            self._logger.info("Health checks passed")
        else:
            self._logger.error(f"Health checks failed: {result.issues}")

        return result

    def check_cooldown_complete(self, cooldown_seconds: int) -> bool:
        """PrÃ¼ft ob Cooldown abgelaufen ist."""
        if not self._current_request or not self._current_request.approved_at:
            return False

        elapsed = (datetime.utcnow() - self._current_request.approved_at).total_seconds()
        return elapsed >= cooldown_seconds

    def start_gradual_restart(self):
        """Startet Gradual Restart."""
        if not self._gradual_enabled:
            self._position_limit_factor = 1.0
            self._current_request.stage = RecoveryStage.COMPLETE
            return

        self._position_limit_factor = self._initial_factor
        self._current_request.stage = RecoveryStage.GRADUAL_RESTART

        self._logger.info(
            f"Gradual restart started: position_limit_factor={self._initial_factor}"
        )

    def update_gradual_restart(self) -> float:
        """
        Aktualisiert Gradual Restart basierend auf Zeit.

        Returns:
            Aktueller position_limit_factor
        """
        if not self._current_request or not self._current_request.approved_at:
            return self._position_limit_factor

        if self._current_request.stage != RecoveryStage.GRADUAL_RESTART:
            return self._position_limit_factor

        elapsed = (datetime.utcnow() - self._current_request.approved_at).total_seconds()

        # Finde passenden Factor basierend auf Zeit
        new_factor = self._initial_factor
        for interval, factor in zip(self._intervals, self._factors):
            if elapsed >= interval:
                new_factor = factor

        if new_factor != self._position_limit_factor:
            self._logger.info(
                f"Position limit escalated: {self._position_limit_factor} â†’ {new_factor}"
            )
            self._position_limit_factor = new_factor

        # Check ob vollstÃ¤ndig
        if self._position_limit_factor >= 1.0:
            self._current_request.stage = RecoveryStage.COMPLETE
            self._logger.info("Gradual restart complete")

        return self._position_limit_factor

    @property
    def position_limit_factor(self) -> float:
        """Aktueller Position Limit Factor."""
        return self._position_limit_factor

    @property
    def current_stage(self) -> Optional[RecoveryStage]:
        """Aktuelle Recovery Stage."""
        if self._current_request:
            return self._current_request.stage
        return None
```

### 3.5 Acceptance Criteria

- [ ] Multi-Stage Recovery Workflow
- [ ] Approval Code Validation
- [ ] Health Check vor Recovery
- [ ] Cooldown mit konfigurierbarer Dauer
- [ ] Gradual Restart mit Position Limits
- [ ] Eskalation der Limits Ã¼ber Zeit
- [ ] Dual-Approval Option (fÃ¼r Production)
- [ ] Integration Tests fÃ¼r kompletten Workflow

---

## ğŸŸ¢ Phase 4: Persistence & Audit

**Ziel:** Persistente State-Speicherung und lÃ¼ckenloser Audit-Trail.

**Dauer:** 2-3 Tage

### 4.1 Persistence-Strategie

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PERSISTENCE & AUDIT                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚ STATE PERSISTENCE                         â”‚                 â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                 â”‚
â”‚  â”‚ â€¢ JSON File (simple, portable)            â”‚                 â”‚
â”‚  â”‚ â€¢ Atomic writes (tmp â†’ rename)            â”‚                 â”‚
â”‚  â”‚ â€¢ Backup before overwrite                 â”‚                 â”‚
â”‚  â”‚ â€¢ Load on startup                         â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚ AUDIT TRAIL                               â”‚                 â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                 â”‚
â”‚  â”‚ â€¢ Append-only Log (JSONL)                 â”‚                 â”‚
â”‚  â”‚ â€¢ Rotation (daily/size-based)             â”‚                 â”‚
â”‚  â”‚ â€¢ Immutable Events                        â”‚                 â”‚
â”‚  â”‚ â€¢ Retention Policy (90 days)              â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚ MONITORING EXPORT                         â”‚                 â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                 â”‚
â”‚  â”‚ â€¢ Prometheus Metrics (optional)           â”‚                 â”‚
â”‚  â”‚ â€¢ Alerting Webhooks                       â”‚                 â”‚
â”‚  â”‚ â€¢ Email Notifications                     â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 Deliverables

| Datei | Beschreibung |
|-------|--------------|
| `src/risk_layer/kill_switch/persistence.py` | State Persistence |
| `src/risk_layer/kill_switch/audit.py` | Audit Trail Logger |
| `tests/risk_layer/kill_switch/test_persistence.py` | Persistence Tests |

**Geplant (TODO):**
- notifications.py - Alert/Notification System
- test_audit.py - Audit Tests

### 4.3 Implementierung

```python
# src/risk_layer/kill_switch/persistence.py
"""State Persistence fÃ¼r Kill Switch."""

import json
import os
import shutil
from datetime import datetime
from pathlib import Path
from typing import Optional
import logging

from .state import KillSwitchState


class StatePersistence:
    """
    Persistiert Kill Switch State auf Disk.

    Features:
    - Atomic writes (Crash-safe)
    - Automatic backup
    - State recovery on startup
    """

    def __init__(
        self,
        state_file: str,
        backup_dir: Optional[str] = None,
        logger: Optional[logging.Logger] = None,
    ):
        self.state_file = Path(state_file)
        self.backup_dir = Path(backup_dir) if backup_dir else self.state_file.parent / "backups"
        self._logger = logger or logging.getLogger(__name__)

        # Directories erstellen
        self.state_file.parent.mkdir(parents=True, exist_ok=True)
        self.backup_dir.mkdir(parents=True, exist_ok=True)

    def save(
        self,
        state: KillSwitchState,
        killed_at: Optional[datetime] = None,
        trigger_reason: Optional[str] = None,
    ):
        """
        Speichert aktuellen State.

        Args:
            state: Aktueller Kill Switch State
            killed_at: Zeitpunkt des Triggers (falls KILLED)
            trigger_reason: Grund fÃ¼r Trigger
        """
        data = {
            "state": state.name,
            "saved_at": datetime.utcnow().isoformat(),
            "killed_at": killed_at.isoformat() if killed_at else None,
            "trigger_reason": trigger_reason,
            "version": "1.0",
        }

        # Atomic write: tmp â†’ rename
        tmp_file = self.state_file.with_suffix(".tmp")

        try:
            with open(tmp_file, "w") as f:
                json.dump(data, f, indent=2)

            # Backup existierende Datei
            if self.state_file.exists():
                backup_name = f"state_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}.json"
                shutil.copy(self.state_file, self.backup_dir / backup_name)

            # Atomic rename
            tmp_file.rename(self.state_file)

            self._logger.debug(f"State saved: {state.name}")

        except Exception as e:
            self._logger.error(f"Failed to save state: {e}")
            if tmp_file.exists():
                tmp_file.unlink()
            raise

    def load(self) -> Optional[dict]:
        """
        LÃ¤dt gespeicherten State.

        Returns:
            State-Dict oder None wenn nicht vorhanden
        """
        if not self.state_file.exists():
            return None

        try:
            with open(self.state_file) as f:
                data = json.load(f)

            self._logger.info(f"State loaded: {data.get('state')}")
            return data

        except json.JSONDecodeError as e:
            self._logger.error(f"Corrupt state file: {e}")
            return None

    def clear(self):
        """LÃ¶scht gespeicherten State."""
        if self.state_file.exists():
            self.state_file.unlink()
            self._logger.info("State cleared")
```

```python
# src/risk_layer/kill_switch/audit.py
"""Audit Trail fÃ¼r Kill Switch Events."""

import json
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Optional
import logging
import gzip
import shutil

from .state import KillSwitchEvent


class AuditTrail:
    """
    Append-only Audit Log fÃ¼r Kill Switch Events.

    Features:
    - JSONL Format (ein Event pro Zeile)
    - Automatische Rotation
    - Retention Policy
    - Compression fÃ¼r alte Logs
    """

    def __init__(
        self,
        audit_dir: str,
        retention_days: int = 90,
        max_file_size_mb: int = 10,
        logger: Optional[logging.Logger] = None,
    ):
        self.audit_dir = Path(audit_dir)
        self.retention_days = retention_days
        self.max_file_size_bytes = max_file_size_mb * 1024 * 1024
        self._logger = logger or logging.getLogger(__name__)

        self.audit_dir.mkdir(parents=True, exist_ok=True)
        self._current_file = self._get_current_file()

    def _get_current_file(self) -> Path:
        """Gibt aktuelle Audit-Datei zurÃ¼ck."""
        today = datetime.utcnow().strftime("%Y-%m-%d")
        return self.audit_dir / f"kill_switch_audit_{today}.jsonl"

    def log_event(self, event: KillSwitchEvent):
        """
        Loggt ein Event in den Audit Trail.

        Args:
            event: Kill Switch Event
        """
        # PrÃ¼fe ob Rotation nÃ¶tig
        self._maybe_rotate()

        # Event serialisieren
        event_data = {
            "timestamp": event.timestamp.isoformat(),
            "previous_state": event.previous_state.name,
            "new_state": event.new_state.name,
            "trigger_reason": event.trigger_reason,
            "triggered_by": event.triggered_by,
            "metadata": event.metadata,
        }

        # Append to file
        with open(self._current_file, "a") as f:
            f.write(json.dumps(event_data) + "\n")

        self._logger.debug(f"Audit event logged: {event.new_state.name}")

    def get_events(
        self,
        since: Optional[datetime] = None,
        until: Optional[datetime] = None,
        limit: int = 100,
    ) -> List[dict]:
        """
        Liest Events aus dem Audit Trail.

        Args:
            since: Events ab diesem Zeitpunkt
            until: Events bis zu diesem Zeitpunkt
            limit: Maximale Anzahl Events

        Returns:
            Liste von Event-Dicts
        """
        events = []

        # Alle relevanten Dateien finden
        for audit_file in sorted(self.audit_dir.glob("kill_switch_audit_*.jsonl")):
            with open(audit_file) as f:
                for line in f:
                    try:
                        event = json.loads(line.strip())
                        event_time = datetime.fromisoformat(event["timestamp"])

                        if since and event_time < since:
                            continue
                        if until and event_time > until:
                            continue

                        events.append(event)

                        if len(events) >= limit:
                            return events

                    except json.JSONDecodeError:
                        continue

        return events

    def _maybe_rotate(self):
        """Rotiert Datei wenn nÃ¶tig."""
        # Check ob neue Datei fÃ¼r neuen Tag
        new_file = self._get_current_file()
        if new_file != self._current_file:
            self._compress_old_file(self._current_file)
            self._current_file = new_file

        # Check DateigrÃ¶ÃŸe
        if self._current_file.exists():
            if self._current_file.stat().st_size > self.max_file_size_bytes:
                # Rotate mit Suffix
                suffix = datetime.utcnow().strftime("%H%M%S")
                rotated = self._current_file.with_suffix(f".{suffix}.jsonl")
                self._current_file.rename(rotated)
                self._compress_old_file(rotated)

    def _compress_old_file(self, file: Path):
        """Komprimiert alte Audit-Datei."""
        if not file.exists():
            return

        gz_file = file.with_suffix(file.suffix + ".gz")
        with open(file, 'rb') as f_in:
            with gzip.open(gz_file, 'wb') as f_out:
                shutil.copyfileobj(f_in, f_out)

        file.unlink()
        self._logger.debug(f"Compressed: {file.name}")

    def cleanup_old_files(self):
        """LÃ¶scht Dateien Ã¤lter als Retention Period."""
        cutoff = datetime.utcnow() - timedelta(days=self.retention_days)

        for file in self.audit_dir.glob("kill_switch_audit_*"):
            try:
                # Datum aus Dateiname extrahieren
                date_str = file.stem.split("_")[-1].split(".")[0]
                file_date = datetime.strptime(date_str, "%Y-%m-%d")

                if file_date < cutoff:
                    file.unlink()
                    self._logger.info(f"Deleted old audit file: {file.name}")

            except (ValueError, IndexError):
                continue
```

### 4.4 Acceptance Criteria

- [ ] State Persistence mit atomic writes
- [ ] Automatic backup vor Ã¼berschreiben
- [ ] State recovery on startup
- [ ] Append-only Audit Log (JSONL)
- [ ] Automatische Log-Rotation (daily + size)
- [ ] Retention Policy (90 Tage)
- [ ] Compression fÃ¼r alte Logs
- [ ] Query-API fÃ¼r Events
- [ ] Unit Tests fÃ¼r Persistence
- [ ] Unit Tests fÃ¼r Audit Trail

---

## ğŸ”µ Phase 5: Integration & API

**Ziel:** Nahtlose Integration in Peak_Trade und externes API.

**Dauer:** 3-4 Tage

### 5.1 Integration Points

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INTEGRATION POINTS                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                   RISK LAYER                             â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚
â”‚  â”‚  â”‚ Layer 1  â”‚â†’ â”‚ Layer 2  â”‚â†’ â”‚ Layer 3  â”‚â†’ â”‚ Layer 4  â”‚ â”‚   â”‚
â”‚  â”‚  â”‚Pre-Trade â”‚  â”‚ Position â”‚  â”‚Portfolio â”‚  â”‚Kill Switchâ”‚ â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                                  â”‚
â”‚                              â–¼                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              EXECUTION LAYER                             â”‚   â”‚
â”‚  â”‚  check_kill_switch() â†’ BLOCK if killed                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                                  â”‚
â”‚                              â–¼                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              CLI / API                                   â”‚   â”‚
â”‚  â”‚  â€¢ kill_switch status                                   â”‚   â”‚
â”‚  â”‚  â€¢ kill_switch trigger --reason "..."                   â”‚   â”‚
â”‚  â”‚  â€¢ kill_switch recover --code "..."                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 Deliverables

| Datei | Beschreibung |
|-------|--------------|
| `src/risk_layer/kill_switch/cli.py` | CLI Commands |

**Geplant (TODO):**
- integration.py - Integration mit Risk Layer
- api.py - REST API (optional)
- execution_gate.py - Kill Switch Gate fÃ¼r Execution
- kill_switch_ctl.sh - Operator Control Script

### 5.3 CLI Interface

```bash
# Kill Switch Control CLI

# Status abfragen
python -m peak_trade.risk.kill_switch status
# Output:
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
# â”‚ KILL SWITCH STATUS                     â”‚
# â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
# â”‚ State:         ğŸŸ¢ ACTIVE               â”‚
# â”‚ Last Trigger:  -                       â”‚
# â”‚ Uptime:        3d 14h 22m              â”‚
# â”‚ Triggers:      Drawdown: âœ“  Daily: âœ“   â”‚
# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

# Manueller Trigger
python -m peak_trade.risk.kill_switch trigger \
  --reason "Manual stop for maintenance" \
  --confirm

# Recovery starten
python -m peak_trade.risk.kill_switch recover \
  --code "EMERGENCY_RECOVERY_2025" \
  --reason "Maintenance complete"

# Audit Trail anzeigen
python -m peak_trade.risk.kill_switch audit \
  --since "2025-01-01" \
  --limit 50

# Health Check
python -m peak_trade.risk.kill_switch health
```

### 5.4 Execution Gate

```python
# src/live/execution_gate.py
"""Execution Gate mit Kill Switch Integration."""

from typing import Optional
from src.risk.kill_switch import KillSwitch


class TradingBlockedError(Exception):
    """Trading ist durch Kill Switch blockiert."""
    pass


class ExecutionGate:
    """
    Gate fÃ¼r Order-Execution.

    PrÃ¼ft Kill Switch vor jeder Order-AusfÃ¼hrung.
    """

    def __init__(self, kill_switch: KillSwitch):
        self._kill_switch = kill_switch

    def check_can_execute(self) -> bool:
        """
        PrÃ¼ft ob Execution erlaubt ist.

        Returns:
            True wenn erlaubt

        Raises:
            TradingBlockedError wenn Kill Switch aktiv
        """
        if self._kill_switch.check_and_block():
            raise TradingBlockedError(
                f"Trading blocked: Kill Switch is {self._kill_switch.state.name}"
            )
        return True

    def execute_with_gate(self, order_func, *args, **kwargs):
        """
        FÃ¼hrt Order-Funktion mit Gate aus.

        Args:
            order_func: Funktion die Order ausfÃ¼hrt
            *args, **kwargs: Argumente fÃ¼r order_func

        Returns:
            Ergebnis von order_func

        Raises:
            TradingBlockedError wenn blockiert
        """
        self.check_can_execute()
        return order_func(*args, **kwargs)
```

### 5.5 Acceptance Criteria

- [ ] Integration mit RiskManager (Layer 1-3)
- [ ] Execution Gate fÃ¼r Live-Trading
- [ ] CLI Commands (status, trigger, recover, audit, health)
- [ ] Operator Control Script (Bash)
- [ ] Event Callbacks fÃ¼r andere Module
- [ ] Position Limit Factor Integration (Gradual Restart)
- [ ] Integration Tests fÃ¼r kompletten Flow

---

## ğŸŸ£ Phase 6: Testing & Chaos Engineering

**Ziel:** Robuste Tests und Validierung unter Stress.

**Dauer:** 4-5 Tage

### 6.1 Test-Strategie

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TESTING PYRAMID                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
â”‚                      â”‚   E2E     â”‚  â† Chaos Engineering        â”‚
â”‚                      â”‚   Tests   â”‚    Failure Injection        â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                             â”‚
â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚                   â”‚  Integration    â”‚  â† Multi-Layer Tests     â”‚
â”‚                   â”‚     Tests       â”‚    Recovery Workflows    â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚             â”‚        Unit Tests           â”‚  â† State Machine   â”‚
â”‚             â”‚                             â”‚    Triggers        â”‚
â”‚             â”‚                             â”‚    Persistence     â”‚
â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.2 Deliverables

| Datei | Beschreibung |
|-------|--------------|
| `tests/risk_layer/kill_switch/test_state_machine.py` | State Machine Unit Tests |
| `tests/risk_layer/kill_switch/test_triggers.py` | Trigger Unit Tests |
| `tests/risk_layer/kill_switch/test_recovery.py` | Recovery Unit Tests |
| `tests/risk_layer/kill_switch/test_persistence.py` | Persistence Unit Tests |
| `tests/risk_layer/kill_switch/test_integration.py` | Integration Tests |

**Geplant (TODO):**
- test_chaos.py - Chaos Engineering Tests
- kill_switch_chaos_test.sh - Chaos Test Runner

### 6.3 Chaos Engineering Szenarien

```python
# tests/risk_layer/kill_switch/test_chaos.py
"""Chaos Engineering Tests fÃ¼r Kill Switch."""

import pytest
import threading
import time
import random
from unittest.mock import patch


class TestChaosScenarios:
    """Chaos Engineering Tests."""

    def test_concurrent_triggers(self, kill_switch):
        """
        Szenario: Mehrere gleichzeitige Trigger.

        Validiert:
        - Thread-Safety
        - State-Konsistenz
        - Keine Race Conditions
        """
        results = []

        def trigger_worker(reason):
            result = kill_switch.trigger(reason)
            results.append((reason, result))

        # 10 parallele Trigger
        threads = [
            threading.Thread(target=trigger_worker, args=(f"Trigger-{i}",))
            for i in range(10)
        ]

        for t in threads:
            t.start()
        for t in threads:
            t.join()

        # Genau ein Trigger sollte "erfolgreich" sein (first trigger)
        # Alle anderen sollten True zurÃ¼ckgeben (already killed)
        assert kill_switch.is_killed
        assert all(r[1] for r in results)  # Alle True

    def test_trigger_during_recovery(self, kill_switch):
        """
        Szenario: Trigger wÃ¤hrend Recovery-Phase.

        Validiert:
        - Recovery wird abgebrochen
        - ZurÃ¼ck zu KILLED State
        """
        kill_switch.trigger("Initial")
        kill_switch.request_recovery("operator")

        assert kill_switch.state.name == "RECOVERING"

        # Trigger wÃ¤hrend Recovery
        kill_switch.trigger("New Emergency")

        assert kill_switch.state.name == "KILLED"

    def test_persistence_crash_recovery(self, kill_switch, tmp_path):
        """
        Szenario: Crash wÃ¤hrend State-Ã„nderung.

        Validiert:
        - State Recovery nach Crash
        - Keine korrupten Dateien
        """
        from src.risk.kill_switch.persistence import StatePersistence

        persistence = StatePersistence(str(tmp_path / "state.json"))

        # Trigger und speichern
        kill_switch.trigger("Pre-Crash")
        persistence.save(kill_switch.state, trigger_reason="Pre-Crash")

        # Simulate Crash: Neue Instanz
        new_switch = create_kill_switch()
        loaded = persistence.load()

        assert loaded["state"] == "KILLED"
        assert loaded["trigger_reason"] == "Pre-Crash"

    def test_watchdog_missed_heartbeats(self, watchdog_trigger):
        """
        Szenario: System hÃ¤ngt, kein Heartbeat.

        Validiert:
        - Watchdog erkennt missed heartbeats
        - Trigger nach max_missed
        """
        # Simulate: Kein Heartbeat
        for _ in range(5):
            result = watchdog_trigger.check({})
            if result.should_trigger:
                break
            time.sleep(0.1)

        assert result.should_trigger
        assert "heartbeat" in result.reason.lower()

    def test_rapid_kill_recover_cycles(self, kill_switch):
        """
        Szenario: Schnelle Kill/Recover Zyklen.

        Validiert:
        - Cooldown wird respektiert
        - State-Konsistenz
        - Keine Memory Leaks
        """
        for i in range(100):
            kill_switch.trigger(f"Cycle-{i}")
            kill_switch.request_recovery("operator")

            # Cooldown erzwingen
            with patch.object(kill_switch, "_recovery_cooldown", 0):
                kill_switch.complete_recovery()

        assert kill_switch.is_active
        assert len(kill_switch.get_audit_trail()) == 300  # 3 Events pro Zyklus
```

### 6.4 Acceptance Criteria

- [ ] Unit Test Coverage > 90%
- [ ] Integration Tests fÃ¼r alle Workflows
- [ ] Chaos Tests fÃ¼r Concurrency
- [ ] Chaos Tests fÃ¼r Crash Recovery
- [ ] Chaos Tests fÃ¼r Rapid Cycles
- [ ] Performance Tests (10k Triggers)
- [ ] Memory Leak Tests
- [ ] Stress Tests unter Last

---

## âšª Phase 7: Dokumentation & Runbooks

**Ziel:** VollstÃ¤ndige Operator-Dokumentation.

**Dauer:** 2-3 Tage

### 7.1 Deliverables

| Datei | Beschreibung |
|-------|--------------|
| `docs/risk/KILL_SWITCH.md` | Technische Dokumentation |
| `docs/ops/KILL_SWITCH_RUNBOOK.md` | Operator Runbook |
| `docs/ops/KILL_SWITCH_TROUBLESHOOTING.md` | Troubleshooting Guide |
| `docs/risk/KILL_SWITCH_ARCHITECTURE.md` | Architektur-Diagramme |

### 7.2 Runbook-Inhalte

```markdown
# Kill Switch Operator Runbook

## Emergency Procedures

### ğŸš¨ Manueller Kill Switch Trigger

**Wann:**
- VerdÃ¤chtiges Marktverhalten
- System-Anomalien
- Geplante Wartung

**Schritte:**
1. Terminal Ã¶ffnen
2. `cd ~/Peak_Trade && source .venv/bin/activate`
3. `python -m peak_trade.risk.kill_switch trigger --reason "GRUND" --confirm`
4. BestÃ¤tigung abwarten
5. Status prÃ¼fen: `python -m peak_trade.risk.kill_switch status`

### ğŸ”„ Recovery nach Kill Switch

**Voraussetzungen:**
- Kill Switch ist im KILLED State
- Trigger-Grund wurde behoben
- System Health ist OK

**Schritte:**
1. Health Check: `python -m peak_trade.risk.kill_switch health`
2. Recovery starten:
   ```bash
   python -m peak_trade.risk.kill_switch recover \
     --code "EMERGENCY_RECOVERY_2025" \
     --reason "Wartung abgeschlossen"
   ```
3. Cooldown abwarten (5 Minuten)
4. Status prÃ¼fen: Position Limits sind zunÃ¤chst bei 50%
5. Nach 1h: Position Limits auf 75%
6. Nach 2h: Position Limits auf 100%

### ğŸ“Š Audit Trail prÃ¼fen

```bash
# Letzte 50 Events
python -m peak_trade.risk.kill_switch audit --limit 50

# Events der letzten 24h
python -m peak_trade.risk.kill_switch audit --since "$(date -v-1d +%Y-%m-%d)"
```
```

### 7.3 Acceptance Criteria

- [ ] Technische Dokumentation vollstÃ¤ndig
- [ ] Operator Runbook mit Schritt-fÃ¼r-Schritt
- [ ] Troubleshooting Guide mit hÃ¤ufigen Problemen
- [ ] Architektur-Diagramme (Mermaid/PlantUML)
- [ ] CLI Command Reference
- [ ] API Reference (falls REST API)
- [ ] Beispiel-Konfigurationen

---

## ğŸ“ˆ Metriken & Success Criteria

### MVP Success Criteria

| Kriterium | Ziel | Messung |
|-----------|------|---------|
| State Machine Robustheit | 100% | Unit Test Coverage |
| Trigger Latency | < 100ms | Performance Test |
| Recovery Time | < 10 Minuten | Integration Test |
| Audit Completeness | 100% Events | Audit Test |
| Crash Recovery | 100% | Chaos Test |
| Documentation | 100% | Review |

### Post-MVP Metriken

| Metrik | Tracking |
|--------|----------|
| False Positive Rate | Trigger ohne echten Notfall |
| Mean Time to Recover | Zeit von KILLED zu ACTIVE |
| Trigger Response Time | Zeit bis System tatsÃ¤chlich stoppt |
| Audit Query Performance | Zeit fÃ¼r Audit-Abfragen |

---

## âš ï¸ Risiken & Mitigations

| Risiko | Impact | Wahrscheinlichkeit | Mitigation |
|--------|--------|-------------------|------------|
| Kill Switch selbst versagt | KRITISCH | Niedrig | Watchdog, separate Instanz |
| False Positives | Mittel | Mittel | Tunable Thresholds, Cooldowns |
| Recovery zu frÃ¼h | Hoch | Niedrig | Cooldown, Approval Code |
| Audit Log korrupt | Mittel | Niedrig | Append-only, Backups |
| Concurrent Access Issues | Hoch | Mittel | RLock, Thread-Safety Tests |

---

## ğŸ¯ Zusammenfassung

**Emergency Kill Switch** ist Layer 4 der Defense-in-Depth Architektur und die **letzte Verteidigungslinie** gegen unkontrollierte Trading-Verluste.

**Key Features:**
- âœ… Robuste State Machine (ACTIVE â†’ KILLED â†’ RECOVERING â†’ ACTIVE)
- âœ… Multiple Trigger-Mechanismen (Threshold, Watchdog, Manual, External)
- âœ… Kontrollierte Recovery (Approval, Cooldown, Gradual Restart)
- âœ… Persistenter State (Crash-safe)
- âœ… LÃ¼ckenloser Audit Trail
- âœ… CLI & API Integration
- âœ… Chaos Engineering validiert

**Timeline:** 4-5 Wochen fÃ¼r vollstÃ¤ndige Implementierung

**PrioritÃ¤t:** ğŸ”´ KRITISCH â€“ Blocker fÃ¼r jegliches Live-Trading

---

**Erstellt von:** Peak_Risk (Chief Risk Officer)  
**Reviewed by:** Peak_Trade Lead Engineer  
**Status:** ğŸ“‹ GEPLANT â€“ Bereit fÃ¼r Implementation
